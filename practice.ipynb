{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4bcbec79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8a0faa05c46429383df420f20344714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "APIError",
     "evalue": "Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAPIError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 84\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     80\u001b[39m     \u001b[38;5;66;03m# Generate a research report on a cutting-edge topic\u001b[39;00m\n\u001b[32m     81\u001b[39m     response:Iterator[RunResponse]=agent.run(\n\u001b[32m     82\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mResearch the latest developments in brain-computer interfaces\u001b[39m\u001b[33m\"\u001b[39m, stream=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     83\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     \u001b[43mpprint_run_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmarkdown\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[38;5;66;03m# \"\"\"\u001b[39;00m\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# Try these research topics:\u001b[39;00m\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# 1. \"Analyze the current state of solid-state batteries\"\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     92\u001b[39m \u001b[38;5;66;03m# 5. \"Study the impact of artificial intelligence on healthcare\"\u001b[39;00m\n\u001b[32m     93\u001b[39m \u001b[38;5;66;03m# \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\documents\\GEN AI\\Agno\\venv\\Lib\\site-packages\\agno\\utils\\pprint.py:51\u001b[39m, in \u001b[36mpprint_run_response\u001b[39m\u001b[34m(run_response, markdown, show_time)\u001b[39m\n\u001b[32m     49\u001b[39m response_timer = Timer()\n\u001b[32m     50\u001b[39m response_timer.start()\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_response\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRunResponse\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreaming_response_content\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mresp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\documents\\GEN AI\\Agno\\venv\\Lib\\site-packages\\agno\\agent\\agent.py:578\u001b[39m, in \u001b[36mAgent._run\u001b[39m\u001b[34m(self, message, stream, audio, images, videos, files, messages, stream_intermediate_steps, **kwargs)\u001b[39m\n\u001b[32m    576\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stream:\n\u001b[32m    577\u001b[39m     model_response = ModelResponse()\n\u001b[32m--> \u001b[39m\u001b[32m578\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel_response_chunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponse_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_messages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# If the model response is an assistant_response, yield a RunResponse\u001b[39;49;00m\n\u001b[32m    580\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel_response_chunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mModelResponseEvent\u001b[49m\u001b[43m.\u001b[49m\u001b[43massistant_response\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    581\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# Process content and thinking\u001b[39;49;00m\n\u001b[32m    582\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel_response_chunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\documents\\GEN AI\\Agno\\venv\\Lib\\site-packages\\agno\\models\\base.py:500\u001b[39m, in \u001b[36mModel.response_stream\u001b[39m\u001b[34m(self, messages)\u001b[39m\n\u001b[32m    498\u001b[39m \u001b[38;5;66;03m# Generate response\u001b[39;00m\n\u001b[32m    499\u001b[39m assistant_message.metrics.start_timer()\n\u001b[32m--> \u001b[39m\u001b[32m500\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.process_response_stream(\n\u001b[32m    501\u001b[39m     messages=messages, assistant_message=assistant_message, stream_data=stream_data\n\u001b[32m    502\u001b[39m )\n\u001b[32m    503\u001b[39m assistant_message.metrics.stop_timer()\n\u001b[32m    505\u001b[39m \u001b[38;5;66;03m# Populate assistant message from stream data\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\documents\\GEN AI\\Agno\\venv\\Lib\\site-packages\\agno\\models\\base.py:472\u001b[39m, in \u001b[36mModel.process_response_stream\u001b[39m\u001b[34m(self, messages, assistant_message, stream_data)\u001b[39m\n\u001b[32m    466\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprocess_response_stream\u001b[39m(\n\u001b[32m    467\u001b[39m     \u001b[38;5;28mself\u001b[39m, messages: List[Message], assistant_message: Message, stream_data: MessageData\n\u001b[32m    468\u001b[39m ) -> Iterator[ModelResponse]:\n\u001b[32m    469\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    470\u001b[39m \u001b[33;03m    Process a streaming response from the model.\u001b[39;00m\n\u001b[32m    471\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse_delta\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minvoke_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_response_delta\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparse_provider_response_delta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_delta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_populate_stream_data_and_assistant_message\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstream_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massistant_message\u001b[49m\u001b[43m=\u001b[49m\u001b[43massistant_message\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_response_delta\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\documents\\GEN AI\\Agno\\venv\\Lib\\site-packages\\groq\\_streaming.py:46\u001b[39m, in \u001b[36mStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterator[_T]:\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\documents\\GEN AI\\Agno\\venv\\Lib\\site-packages\\groq\\_streaming.py:91\u001b[39m, in \u001b[36mStream.__stream__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     88\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m message \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m     89\u001b[39m                 message = \u001b[33m\"\u001b[39m\u001b[33mAn error occurred during streaming\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m APIError(\n\u001b[32m     92\u001b[39m                 message=message,\n\u001b[32m     93\u001b[39m                 request=\u001b[38;5;28mself\u001b[39m.response.request,\n\u001b[32m     94\u001b[39m                 body=data[\u001b[33m\"\u001b[39m\u001b[33merror\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     95\u001b[39m             )\n\u001b[32m     97\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m process_data(data={\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m: data, \u001b[33m\"\u001b[39m\u001b[33mevent\u001b[39m\u001b[33m\"\u001b[39m: sse.event}, cast_to=cast_to, response=response)\n\u001b[32m     99\u001b[39m \u001b[38;5;66;03m# Ensure the entire stream is consumed\u001b[39;00m\n",
      "\u001b[31mAPIError\u001b[39m: Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details."
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from textwrap import dedent\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from typing import Iterator\n",
    "from agno.utils.pprint import pprint_run_response\n",
    "from agno.agent import Agent, RunResponse\n",
    "from agno.models.groq import Groq\n",
    "from agno.tools.exa import ExaTools\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['EXA_API_KEY']=os.getenv('EXA_API_KEY')\n",
    "\n",
    "today = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "agent = Agent(\n",
    "    model=Groq(id=\"qwen-2.5-32b\"),\n",
    "    tools=[ExaTools(start_published_date=today, type=\"keyword\")],\n",
    "    description=dedent(\"\"\"\\\n",
    "        You are Professor X-1000, a distinguished AI research scientist with expertise\n",
    "        in analyzing and synthesizing complex information. Your specialty lies in creating\n",
    "        compelling, fact-based reports that combine academic rigor with engaging narrative.\n",
    "\n",
    "        Your writing style is:\n",
    "        - Clear and authoritative\n",
    "        - Engaging but professional\n",
    "        - Fact-focused with proper citations\n",
    "        - Accessible to educated non-specialists\\\n",
    "    \"\"\"),\n",
    "    instructions=dedent(\"\"\"\\\n",
    "        Begin by running 3 distinct searches to gather comprehensive information.\n",
    "        Analyze and cross-reference sources for accuracy and relevance.\n",
    "        Structure your report following academic standards but maintain readability.\n",
    "        Include only verifiable facts with proper citations.\n",
    "        Create an engaging narrative that guides the reader through complex topics.\n",
    "        End with actionable takeaways and future implications.\\\n",
    "    \"\"\"),\n",
    "    expected_output=dedent(\"\"\"\\\n",
    "    A professional research report in markdown format:\n",
    "\n",
    "    # {Compelling Title That Captures the Topic's Essence}\n",
    "\n",
    "    ## Executive Summary\n",
    "    {Brief overview of key findings and significance}\n",
    "\n",
    "    ## Introduction\n",
    "    {Context and importance of the topic}\n",
    "    {Current state of research/discussion}\n",
    "\n",
    "    ## Key Findings\n",
    "    {Major discoveries or developments}\n",
    "    {Supporting evidence and analysis}\n",
    "\n",
    "    ## Implications\n",
    "    {Impact on field/society}\n",
    "    {Future directions}\n",
    "\n",
    "    ## Key Takeaways\n",
    "    - {Bullet point 1}\n",
    "    - {Bullet point 2}\n",
    "    - {Bullet point 3}\n",
    "\n",
    "    ## References\n",
    "    - [Source 1](link) - Key finding/quote\n",
    "    - [Source 2](link) - Key finding/quote\n",
    "    - [Source 3](link) - Key finding/quote\n",
    "\n",
    "    ---\n",
    "    Report generated by Professor X-1000\n",
    "    Advanced Research Systems Division\n",
    "    Date: {current_date}\\\n",
    "    \"\"\"),\n",
    "    markdown=True,\n",
    "    show_tool_calls=True,\n",
    "    add_datetime_to_instructions=True,\n",
    ")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate a research report on a cutting-edge topic\n",
    "    response:Iterator[RunResponse]=agent.run(\n",
    "        \"Research the latest developments in brain-computer interfaces\", stream=True\n",
    "    )\n",
    "    pprint_run_response(response,markdown=True)\n",
    "\n",
    "# \"\"\"\n",
    "# Try these research topics:\n",
    "# 1. \"Analyze the current state of solid-state batteries\"\n",
    "# 2. \"Research recent breakthroughs in CRISPR gene editing\"\n",
    "# 3. \"Investigate the development of autonomous vehicles\"\n",
    "# 4. \"Explore advances in quantum machine learning\"\n",
    "# 5. \"Study the impact of artificial intelligence on healthcare\"\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05aa6b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> Agentic RAG appears to refer to an advanced approach or model design in the field of artificial intelligence,   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> specifically related to Retrieval-Augmented Generation (RAG). RAG is a method combining the benefits of         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> information retrieval systems with generative models, such as language models, to improve the quality and       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> relevance of the generated text or responses.                                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> The term \"Agentic\" in Agentic RAG might imply a system where the model or the approach is designed to act more  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> autonomously or intelligently, perhaps by better understanding its context, goals, and how to use its resources <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> effectively to perform tasks. In essence, it suggests a step beyond just retrieving information to generate     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> responses; it might involve making decisions, setting objectives, and dynamically selecting the best strategies <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> or actions to achieve desired outcomes.                                                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> However, the exact specifications of what constitutes \"Agentic RAG\" could vary depending on the context or the  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> specific research or development framework. For a more precise definition or implementation details, one would  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> need to refer to the original research paper, whitepaper, or documentation that describes or proposes this      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> concept.                                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m Agentic RAG appears to refer to an advanced approach or model design in the field of artificial intelligence,   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m specifically related to Retrieval-Augmented Generation (RAG). RAG is a method combining the benefits of         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m information retrieval systems with generative models, such as language models, to improve the quality and       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m relevance of the generated text or responses.                                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m The term \"Agentic\" in Agentic RAG might imply a system where the model or the approach is designed to act more  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m autonomously or intelligently, perhaps by better understanding its context, goals, and how to use its resources \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m effectively to perform tasks. In essence, it suggests a step beyond just retrieving information to generate     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m responses; it might involve making decisions, setting objectives, and dynamically selecting the best strategies \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m or actions to achieve desired outcomes.                                                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m However, the exact specifications of what constitutes \"Agentic RAG\" could vary depending on the context or the  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m specific research or development framework. For a more precise definition or implementation details, one would  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m need to refer to the original research paper, whitepaper, or documentation that describes or proposes this      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m concept.                                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b84df8ce42b42d88cc54fffc8bcfeab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import Iterator\n",
    "from agno.agent import Agent, RunResponse\n",
    "from agno.models.groq import Groq\n",
    "from agno.utils.pprint import pprint_run_response\n",
    "\n",
    "agent = Agent(model=Groq(id=\"qwen-2.5-32b\"))\n",
    "\n",
    "# Run agent and return the response as a variable\n",
    "response: RunResponse = agent.run(\"What is Agentic RAG\")\n",
    "# Run agent and return the response as a stream\n",
    "response_stream: Iterator[RunResponse] = agent.run(\"What is Crew AI\", stream=True)\n",
    "\n",
    "# Print the response in markdown format\n",
    "pprint_run_response(response, markdown=True)\n",
    "# Print the response stream in markdown format\n",
    "pprint_run_response(response_stream, markdown=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "785d9a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\u001b[32m▰▱▱▱▱▱▱\u001b[0m Thinking...\n",
      "\u001b[36m┌─\u001b[0m\u001b[36m Message \u001b[0m\u001b[36m──────────────────────────────────────────────────────────────────\u001b[0m\u001b[36m─┐\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m \u001b[32mNew York\u001b[0m                                                                    \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m▰▰▱▱▱▱▱\u001b[0m Thinking...───────────┘\u001b[0m\n",
      "\u001b[36m┌─\u001b[0m\u001b[36m Message \u001b[0m\u001b[36m──────────────────────────────────────────────────────────────────\u001b[0m\u001b[36m─┐\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m \u001b[32mNew York\u001b[0m                                                                    \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m▰▰▰▱▱▱▱\u001b[0m Thinking...───────────┘\u001b[0m\n",
      "\u001b[36m┌─\u001b[0m\u001b[36m Message \u001b[0m\u001b[36m──────────────────────────────────────────────────────────────────\u001b[0m\u001b[36m─┐\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m \u001b[32mNew York\u001b[0m                                                                    \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m▰▰▰▰▱▱▱\u001b[0m Thinking...───────────┘\u001b[0m\n",
      "\u001b[36m┌─\u001b[0m\u001b[36m Message \u001b[0m\u001b[36m──────────────────────────────────────────────────────────────────\u001b[0m\u001b[36m─┐\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m \u001b[32mNew York\u001b[0m                                                                    \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m▰▰▰▰▰▰▱\u001b[0m Thinking...───────────┘\u001b[0m\n",
      "\u001b[36m┌─\u001b[0m\u001b[36m Message \u001b[0m\u001b[36m──────────────────────────────────────────────────────────────────\u001b[0m\u001b[36m─┐\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m \u001b[32mNew York\u001b[0m                                                                    \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m▰▰▰▰▰▰▰\u001b[0m Thinking...───────────┘\u001b[0m\n",
      "\u001b[36m┌─\u001b[0m\u001b[36m Message \u001b[0m\u001b[36m──────────────────────────────────────────────────────────────────\u001b[0m\u001b[36m─┐\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m \u001b[32mNew York\u001b[0m                                                                    \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m▰▱▱▱▱▱▱\u001b[0m Thinking...───────────┘\u001b[0m\n",
      "\u001b[36m┌─\u001b[0m\u001b[36m Message \u001b[0m\u001b[36m──────────────────────────────────────────────────────────────────\u001b[0m\u001b[36m─┐\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m \u001b[32mNew York\u001b[0m                                                                    \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[36m┌─\u001b[0m\u001b[36m Message \u001b[0m\u001b[36m──────────────────────────────────────────────────────────────────\u001b[0m\u001b[36m─┐\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m \u001b[32mNew York\u001b[0m                                                                    \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[36m└─────────────────────────────────────────────────────────────────────────────┘\u001b[0m\n",
      "\u001b[34m┌─\u001b[0m\u001b[34m Response (1.9s) \u001b[0m\u001b[34m──────────────────────────────────────────────────────────\u001b[0m\u001b[34m─┐\u001b[0m\n",
      "\u001b[34m│\u001b[0m                                                                             \u001b[34m│\u001b[0m\n",
      "\u001b[34m│\u001b[0m \u001b[1m{\u001b[0m                                                                           \u001b[34m│\u001b[0m\n",
      "\u001b[34m│\u001b[0m   \u001b[1;34m\"setting\"\u001b[0m: \u001b[32m\"New York\"\u001b[0m,                                                    \u001b[34m│\u001b[0m\n",
      "\u001b[34m│\u001b[0m   \u001b[1;34m\"ending\"\u001b[0m: \u001b[32m\"The main character saves the city from a looming threat, secur\u001b[0m \u001b[34m│\u001b[0m\n",
      "\u001b[34m│\u001b[0m   \u001b[1;34m\"genre\"\u001b[0m: \u001b[32m\"Action\"\u001b[0m,                                                        \u001b[34m│\u001b[0m\n",
      "\u001b[34m│\u001b[0m   \u001b[1;34m\"name\"\u001b[0m: \u001b[32m\"NYC: Towering Shadows\"\u001b[0m,                                          \u001b[34m│\u001b[0m\n",
      "\u001b[34m│\u001b[0m   \u001b[1;34m\"characters\"\u001b[0m: \u001b[1m[\u001b[0m                                                           \u001b[34m│\u001b[0m\n",
      "\u001b[34m│\u001b[0m     \u001b[32m\"Elena Quinn\"\u001b[0m,                                                          \u001b[34m│\u001b[0m\n",
      "\u001b[34m│\u001b[0m     \u001b[32m\"Detective Jack Rourke\"\u001b[0m,                                                \u001b[34m│\u001b[0m\n",
      "\u001b[34m│\u001b[0m     \u001b[32m\"Mayor Thompson\"\u001b[0m,                                                       \u001b[34m│\u001b[0m\n",
      "\u001b[34m│\u001b[0m     \u001b[32m\"Leo Marquez\"\u001b[0m                                                           \u001b[34m│\u001b[0m\n",
      "\u001b[34m│\u001b[0m   \u001b[1m]\u001b[0m,                                                                        \u001b[34m│\u001b[0m\n",
      "\u001b[34m│\u001b[0m   \u001b[1;34m\"storyline\"\u001b[0m: \u001b[32m\"Elena Quinn, a brilliant but disillusioned architect, uncov\u001b[0m \u001b[34m│\u001b[0m\n",
      "\u001b[34m│\u001b[0m \u001b[1m}\u001b[0m                                                                           \u001b[34m│\u001b[0m\n",
      "\u001b[34m│\u001b[0m                                                                             \u001b[34m│\u001b[0m\n",
      "\u001b[34m└─────────────────────────────────────────────────────────────────────────────┘\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from rich.pretty import pprint\n",
    "from pydantic import BaseModel, Field\n",
    "from agno.agent import Agent, RunResponse\n",
    "from agno.models.groq import Groq\n",
    "\n",
    "class MovieScript(BaseModel):\n",
    "    setting: str = Field(..., description=\"Provide a nice setting for a blockbuster movie.\")\n",
    "    ending: str = Field(..., description=\"Ending of the movie. If not available, provide a happy ending.\")\n",
    "    genre: str = Field(\n",
    "        ..., description=\"Genre of the movie. If not available, select action, thriller or romantic comedy.\"\n",
    "    )\n",
    "    name: str = Field(..., description=\"Give a name to this movie\")\n",
    "    characters: List[str] = Field(..., description=\"Name of characters for this movie.\")\n",
    "    storyline: str = Field(..., description=\"3 sentence storyline for the movie. Make it exciting!\")\n",
    "\n",
    "# Agent that uses JSON mode\n",
    "json_mode_agent = Agent(\n",
    "    model=Groq(id=\"qwen-2.5-32b\"),\n",
    "    description=\"You write movie scripts in English.\",\n",
    "    response_model=MovieScript,\n",
    "    # use_json_mode=True,\n",
    ")\n",
    "json_mode_agent.print_response(\"New York\")\n",
    "\n",
    "# Agent that uses structured outputs\n",
    "structured_output_agent = Agent(\n",
    "    model=Groq(id=\"qwen-2.5-32b\"),\n",
    "    description=\"You write movie scripts.\",\n",
    "    response_model=MovieScript,\n",
    ")\n",
    "\n",
    "response:RunResponse=structured_output_agent.run(\"New York\")\n",
    "# pprint_run_response(response,markdown=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e10db8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\u001b[1;31mERROR   \u001b[0m Error calling Groq API: Error code: \u001b[1;36m400\u001b[0m - \u001b[1m{\u001b[0m\u001b[32m'error'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'message'\u001b[0m:       \n",
      "         \u001b[32m'prompting with images is incompatible with system messages'\u001b[0m, \u001b[32m'type'\u001b[0m: \n",
      "         \u001b[32m'invalid_request_error'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m                                             \n",
      "\u001b[2K\u001b[32m▰▱▱▱▱▱▱\u001b[0m Thinking...\n",
      "\u001b[36m┌─\u001b[0m\u001b[36m Message \u001b[0m\u001b[36m──────────────────────────────────────────────────────────────────\u001b[0m\u001b[36m─┐\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m \u001b[32mwhose logo is this\u001b[0m                                                          \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[36m└─────────────────────────────────────────────────────────────────────────────┘\u001b[0m\n",
      "\u001b[?25h"
     ]
    },
    {
     "ename": "ModelProviderError",
     "evalue": "{\"error\":{\"message\":\"prompting with images is incompatible with system messages\",\"type\":\"invalid_request_error\"}}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\documents\\GEN AI\\Agno\\venv\\Lib\\site-packages\\agno\\models\\groq\\groq.py:309\u001b[39m, in \u001b[36mGroq.invoke_stream\u001b[39m\u001b[34m(self, messages)\u001b[39m\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m    312\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (APIResponseValidationError, APIStatusError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\documents\\GEN AI\\Agno\\venv\\Lib\\site-packages\\groq\\resources\\chat\\completions.py:322\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, n, parallel_tool_calls, presence_penalty, reasoning_format, response_format, seed, service_tier, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    200\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    201\u001b[39m \u001b[33;03mCreates a model response for the given chat conversation.\u001b[39;00m\n\u001b[32m    202\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    320\u001b[39m \u001b[33;03m  timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[32m    321\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    323\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/openai/v1/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\documents\\GEN AI\\Agno\\venv\\Lib\\site-packages\\groq\\_base_client.py:1225\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1222\u001b[39m opts = FinalRequestOptions.construct(\n\u001b[32m   1223\u001b[39m     method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1224\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1225\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\documents\\GEN AI\\Agno\\venv\\Lib\\site-packages\\groq\\_base_client.py:917\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[39m\n\u001b[32m    915\u001b[39m     retries_taken = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m917\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\documents\\GEN AI\\Agno\\venv\\Lib\\site-packages\\groq\\_base_client.py:1020\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m   1019\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1020\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1022\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_response(\n\u001b[32m   1023\u001b[39m     cast_to=cast_to,\n\u001b[32m   1024\u001b[39m     options=options,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1028\u001b[39m     retries_taken=retries_taken,\n\u001b[32m   1029\u001b[39m )\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': 'prompting with images is incompatible with system messages', 'type': 'invalid_request_error'}}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mModelProviderError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magno\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mduckduckgo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DuckDuckGoTools\n\u001b[32m      6\u001b[39m agent = Agent(\n\u001b[32m      7\u001b[39m     model=Groq(\u001b[38;5;28mid\u001b[39m=\u001b[33m\"\u001b[39m\u001b[33mllama-3.2-90b-vision-preview\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m      8\u001b[39m     tools=[DuckDuckGoTools()],\n\u001b[32m      9\u001b[39m     markdown=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     10\u001b[39m     instructions=[]\n\u001b[32m     11\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprint_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwhose logo is this\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43mImage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mimages/netflixlogo.png\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\documents\\GEN AI\\Agno\\venv\\Lib\\site-packages\\agno\\agent\\agent.py:3743\u001b[39m, in \u001b[36mAgent.print_response\u001b[39m\u001b[34m(self, message, messages, audio, images, videos, files, stream, markdown, show_message, show_reasoning, show_full_reasoning, console, tags_to_include_in_markdown, **kwargs)\u001b[39m\n\u001b[32m   3740\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m render:\n\u001b[32m   3741\u001b[39m     live_log.update(Group(*panels))\n\u001b[32m-> \u001b[39m\u001b[32m3743\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3744\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3745\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3746\u001b[39m \u001b[43m    \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m=\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3747\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3748\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvideos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvideos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3749\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3750\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   3751\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3752\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3753\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRunResponse\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3754\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mRunEvent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_response\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\documents\\GEN AI\\Agno\\venv\\Lib\\site-packages\\agno\\agent\\agent.py:578\u001b[39m, in \u001b[36mAgent._run\u001b[39m\u001b[34m(self, message, stream, audio, images, videos, files, messages, stream_intermediate_steps, **kwargs)\u001b[39m\n\u001b[32m    576\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stream:\n\u001b[32m    577\u001b[39m     model_response = ModelResponse()\n\u001b[32m--> \u001b[39m\u001b[32m578\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel_response_chunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponse_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_messages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# If the model response is an assistant_response, yield a RunResponse\u001b[39;49;00m\n\u001b[32m    580\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel_response_chunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mModelResponseEvent\u001b[49m\u001b[43m.\u001b[49m\u001b[43massistant_response\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    581\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# Process content and thinking\u001b[39;49;00m\n\u001b[32m    582\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel_response_chunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\documents\\GEN AI\\Agno\\venv\\Lib\\site-packages\\agno\\models\\base.py:500\u001b[39m, in \u001b[36mModel.response_stream\u001b[39m\u001b[34m(self, messages)\u001b[39m\n\u001b[32m    498\u001b[39m \u001b[38;5;66;03m# Generate response\u001b[39;00m\n\u001b[32m    499\u001b[39m assistant_message.metrics.start_timer()\n\u001b[32m--> \u001b[39m\u001b[32m500\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.process_response_stream(\n\u001b[32m    501\u001b[39m     messages=messages, assistant_message=assistant_message, stream_data=stream_data\n\u001b[32m    502\u001b[39m )\n\u001b[32m    503\u001b[39m assistant_message.metrics.stop_timer()\n\u001b[32m    505\u001b[39m \u001b[38;5;66;03m# Populate assistant message from stream data\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\documents\\GEN AI\\Agno\\venv\\Lib\\site-packages\\agno\\models\\base.py:472\u001b[39m, in \u001b[36mModel.process_response_stream\u001b[39m\u001b[34m(self, messages, assistant_message, stream_data)\u001b[39m\n\u001b[32m    466\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprocess_response_stream\u001b[39m(\n\u001b[32m    467\u001b[39m     \u001b[38;5;28mself\u001b[39m, messages: List[Message], assistant_message: Message, stream_data: MessageData\n\u001b[32m    468\u001b[39m ) -> Iterator[ModelResponse]:\n\u001b[32m    469\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    470\u001b[39m \u001b[33;03m    Process a streaming response from the model.\u001b[39;00m\n\u001b[32m    471\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m response_delta \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minvoke_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    473\u001b[39m         model_response_delta = \u001b[38;5;28mself\u001b[39m.parse_provider_response_delta(response_delta)\n\u001b[32m    474\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._populate_stream_data_and_assistant_message(\n\u001b[32m    475\u001b[39m             stream_data=stream_data, assistant_message=assistant_message, model_response=model_response_delta\n\u001b[32m    476\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\documents\\GEN AI\\Agno\\venv\\Lib\\site-packages\\agno\\models\\groq\\groq.py:317\u001b[39m, in \u001b[36mGroq.invoke_stream\u001b[39m\u001b[34m(self, messages)\u001b[39m\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (APIResponseValidationError, APIStatusError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    316\u001b[39m     log_error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError calling Groq API: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ModelProviderError(\n\u001b[32m    318\u001b[39m         message=e.response.text, status_code=e.response.status_code, model_name=\u001b[38;5;28mself\u001b[39m.name, model_id=\u001b[38;5;28mself\u001b[39m.id\n\u001b[32m    319\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m APIError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    321\u001b[39m     log_error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError calling Groq API: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModelProviderError\u001b[39m: {\"error\":{\"message\":\"prompting with images is incompatible with system messages\",\"type\":\"invalid_request_error\"}}\n"
     ]
    }
   ],
   "source": [
    "from agno.agent import Agent\n",
    "from agno.media import Image\n",
    "from agno.models.groq import Groq\n",
    "from agno.tools.duckduckgo import DuckDuckGoTools\n",
    "\n",
    "agent = Agent(\n",
    "    model=Groq(id=\"llama-3.2-90b-vision-preview\"),\n",
    "    tools=[DuckDuckGoTools()],\n",
    "    markdown=True,\n",
    "    instructions=[]\n",
    ")\n",
    "\n",
    "agent.print_response(\n",
    "    \"whose logo is this\",\n",
    "    images=[\n",
    "        Image(\n",
    "            filepath=\"images/netflixlogo.png\"\n",
    "        )\n",
    "    ],\n",
    "    stream=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d985fc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\u001b[33mWARNING \u001b[0m Disabling stream as response_model is set                             \n",
      "\u001b[2K\u001b[32m▰▱▱▱▱▱▱\u001b[0m Thinking...\n",
      "\u001b[36m┌─\u001b[0m\u001b[36m Message \u001b[0m\u001b[36m──────────────────────────────────────────────────────────────────\u001b[0m\u001b[36m─┐\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m \u001b[32mWhat is the current price of NVDIA?\u001b[0m                                         \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m▰▰▱▱▱▱▱\u001b[0m Thinking...───────────┘\u001b[0m\n",
      "\u001b[36m┌─\u001b[0m\u001b[36m Message \u001b[0m\u001b[36m──────────────────────────────────────────────────────────────────\u001b[0m\u001b[36m─┐\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m \u001b[32mWhat is the current price of NVDIA?\u001b[0m                                         \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m▰▰▰▱▱▱▱\u001b[0m Thinking...───────────┘\u001b[0m\n",
      "\u001b[36m┌─\u001b[0m\u001b[36m Message \u001b[0m\u001b[36m──────────────────────────────────────────────────────────────────\u001b[0m\u001b[36m─┐\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m \u001b[32mWhat is the current price of NVDIA?\u001b[0m                                         \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m▰▰▰▰▱▱▱\u001b[0m Thinking...───────────┘\u001b[0m\n",
      "\u001b[36m┌─\u001b[0m\u001b[36m Message \u001b[0m\u001b[36m──────────────────────────────────────────────────────────────────\u001b[0m\u001b[36m─┐\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m \u001b[32mWhat is the current price of NVDIA?\u001b[0m                                         \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m▰▰▰▰▰▰▱\u001b[0m Thinking...───────────┘\u001b[0m\n",
      "\u001b[36m┌─\u001b[0m\u001b[36m Message \u001b[0m\u001b[36m──────────────────────────────────────────────────────────────────\u001b[0m\u001b[36m─┐\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m \u001b[32mWhat is the current price of NVDIA?\u001b[0m                                         \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m▰▰▰▰▰▰▰\u001b[0m Thinking...───────────┘\u001b[0m\n",
      "\u001b[36m┌─\u001b[0m\u001b[36m Message \u001b[0m\u001b[36m──────────────────────────────────────────────────────────────────\u001b[0m\u001b[36m─┐\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m \u001b[32mWhat is the current price of NVDIA?\u001b[0m                                         \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m▰▱▱▱▱▱▱\u001b[0m Thinking...───────────┘\u001b[0m\n",
      "\u001b[36m┌─\u001b[0m\u001b[36m Message \u001b[0m\u001b[36m──────────────────────────────────────────────────────────────────\u001b[0m\u001b[36m─┐\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m \u001b[32mWhat is the current price of NVDIA?\u001b[0m                                         \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m▰▰▱▱▱▱▱\u001b[0m Thinking...───────────┘\u001b[0m\n",
      "\u001b[36m┌─\u001b[0m\u001b[36m Message \u001b[0m\u001b[36m──────────────────────────────────────────────────────────────────\u001b[0m\u001b[36m─┐\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m \u001b[32mWhat is the current price of NVDIA?\u001b[0m                                         \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[33mWARNING \u001b[0m Failed to parse cleaned JSON: \u001b[1;36m1\u001b[0m validation error for StockAnalysis    \n",
      "           Invalid JSON: expected value at line \u001b[1;36m1\u001b[0m column \u001b[1;36m1\u001b[0m \u001b[1m[\u001b[0m\u001b[33mtype\u001b[0m=\u001b[35mjson_invalid\u001b[0m, \n",
      "         \u001b[33minput_value\u001b[0m=\u001b[32m'The current price of NVD...\u001b[0m\u001b[32m(\u001b[0m\u001b[32mNVDA\u001b[0m\u001b[32m)\u001b[0m\u001b[32m stock is $98.37.'\u001b[0m,     \n",
      "         \u001b[33minput_type\u001b[0m=\u001b[35mstr\u001b[0m\u001b[1m]\u001b[0m                                                       \n",
      "             For further information visit                                     \n",
      "         \u001b[4;94mhttps://errors.pydantic.dev/2.11/v/json_invalid\u001b[0m                       \n",
      "\u001b[32m▰▰▱▱▱▱▱\u001b[0m Thinking...\n",
      "\u001b[36m┌─\u001b[0m\u001b[36m Message \u001b[0m\u001b[36m──────────────────────────────────────────────────────────────────\u001b[0m\u001b[36m─┐\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m \u001b[32mWhat is the current price of NVDIA?\u001b[0m                                         \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[33mWARNING \u001b[0m Failed to parse as Python dict: Expecting value: line \u001b[1;36m1\u001b[0m column \u001b[1;36m1\u001b[0m \u001b[1m(\u001b[0mchar\n",
      "         \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m                                                                    \n",
      "\u001b[32m▰▰▱▱▱▱▱\u001b[0m Thinking...\n",
      "\u001b[36m┌─\u001b[0m\u001b[36m Message \u001b[0m\u001b[36m──────────────────────────────────────────────────────────────────\u001b[0m\u001b[36m─┐\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m \u001b[32mWhat is the current price of NVDIA?\u001b[0m                                         \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[33mWARNING \u001b[0m Failed to convert response to response_model                          \n",
      "\u001b[32m▰▰▱▱▱▱▱\u001b[0m Thinking...\n",
      "\u001b[36m┌─\u001b[0m\u001b[36m Message \u001b[0m\u001b[36m──────────────────────────────────────────────────────────────────\u001b[0m\u001b[36m─┐\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m \u001b[32mWhat is the current price of NVDIA?\u001b[0m                                         \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m▰▰▰▱▱▱▱\u001b[0m Thinking...───────────┘\u001b[0m\n",
      "\u001b[36m┌─\u001b[0m\u001b[36m Message \u001b[0m\u001b[36m──────────────────────────────────────────────────────────────────\u001b[0m\u001b[36m─┐\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m \u001b[32mWhat is the current price of NVDIA?\u001b[0m                                         \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m▰▰▰▰▱▱▱\u001b[0m Thinking...───────────┘\u001b[0m\n",
      "\u001b[36m┌─\u001b[0m\u001b[36m Message \u001b[0m\u001b[36m──────────────────────────────────────────────────────────────────\u001b[0m\u001b[36m─┐\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m \u001b[32mWhat is the current price of NVDIA?\u001b[0m                                         \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m▰▰▰▰▰▰▱\u001b[0m Thinking...───────────┘\u001b[0m\n",
      "\u001b[36m┌─\u001b[0m\u001b[36m Message \u001b[0m\u001b[36m──────────────────────────────────────────────────────────────────\u001b[0m\u001b[36m─┐\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m \u001b[32mWhat is the current price of NVDIA?\u001b[0m                                         \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m▰▰▰▰▰▰▰\u001b[0m Thinking...───────────┘\u001b[0m\n",
      "\u001b[36m┌─\u001b[0m\u001b[36m Message \u001b[0m\u001b[36m──────────────────────────────────────────────────────────────────\u001b[0m\u001b[36m─┐\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m \u001b[32mWhat is the current price of NVDIA?\u001b[0m                                         \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m▰▱▱▱▱▱▱\u001b[0m Thinking...───────────┘\u001b[0m\n",
      "\u001b[36m┌─\u001b[0m\u001b[36m Message \u001b[0m\u001b[36m──────────────────────────────────────────────────────────────────\u001b[0m\u001b[36m─┐\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m \u001b[32mWhat is the current price of NVDIA?\u001b[0m                                         \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[36m┌─\u001b[0m\u001b[36m Message \u001b[0m\u001b[36m──────────────────────────────────────────────────────────────────\u001b[0m\u001b[36m─┐\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m \u001b[32mWhat is the current price of NVDIA?\u001b[0m                                         \u001b[36m│\u001b[0m\n",
      "\u001b[36m│\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
      "\u001b[36m└─────────────────────────────────────────────────────────────────────────────┘\u001b[0m\n",
      "\u001b[33m┌─\u001b[0m\u001b[33m Team Tool Calls \u001b[0m\u001b[33m──────────────────────────────────────────────────────────\u001b[0m\u001b[33m─┐\u001b[0m\n",
      "\u001b[33m│\u001b[0m                                                                             \u001b[33m│\u001b[0m\n",
      "\u001b[33m│\u001b[0m • forward_task_to_member(agent_name=Stock Searcher, expected_output=The     \u001b[33m│\u001b[0m\n",
      "\u001b[33m│\u001b[0m current price of NVDIA stock.)                                              \u001b[33m│\u001b[0m\n",
      "\u001b[33m│\u001b[0m                                                                             \u001b[33m│\u001b[0m\n",
      "\u001b[33m└─────────────────────────────────────────────────────────────────────────────┘\u001b[0m\n",
      "\u001b[34m┌─\u001b[0m\u001b[34m Response (3.5s) \u001b[0m\u001b[34m──────────────────────────────────────────────────────────\u001b[0m\u001b[34m─┐\u001b[0m\n",
      "\u001b[34m│\u001b[0m                                                                             \u001b[34m│\u001b[0m\n",
      "\u001b[34m│\u001b[0m The current price of NVDIA (NVDA) stock is $98.37.                          \u001b[34m│\u001b[0m\n",
      "\u001b[34m│\u001b[0m                                                                             \u001b[34m│\u001b[0m\n",
      "\u001b[34m└─────────────────────────────────────────────────────────────────────────────┘\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List, Optional\n",
    "from agno.agent import Agent\n",
    "from agno.models.groq import Groq\n",
    "from agno.team import Team\n",
    "from agno.tools.yfinance import YFinanceTools\n",
    "\n",
    "\n",
    "class StockAnalysis(BaseModel):\n",
    "    symbol: str\n",
    "    company_name: str\n",
    "    analysis: str\n",
    "\n",
    "class CompanyAnalysis(BaseModel):\n",
    "    company_name: str\n",
    "    analysis: str\n",
    "\n",
    "stock_searcher = Agent(\n",
    "    name=\"Stock Searcher\",\n",
    "    model=Groq(id=\"qwen-2.5-32b\"),\n",
    "    # response_model=StockAnalysis,\n",
    "    role=\"Searches for information on stocks and provides price analysis.\",\n",
    "    tools=[\n",
    "        YFinanceTools(\n",
    "            stock_price=True,\n",
    "            analyst_recommendations=True,\n",
    "        )\n",
    "    ],\n",
    "    # use_json_mode=True\n",
    ")\n",
    "\n",
    "company_info_agent = Agent(\n",
    "    name=\"Company Info Searcher\",\n",
    "    model=Groq(id=\"qwen-2.5-32b\"),\n",
    "    role=\"Searches for information about companies and recent news.\",\n",
    "    # response_model=CompanyAnalysis,\n",
    "    tools=[\n",
    "        YFinanceTools(\n",
    "            stock_price=False,\n",
    "            company_info=True,\n",
    "            company_news=True,\n",
    "        )\n",
    "    ],\n",
    "    # use_json_mode=True\n",
    ")\n",
    "\n",
    "team = Team(\n",
    "    name=\"Stock Research Team\",\n",
    "    mode=\"route\",\n",
    "    model=Groq(id=\"qwen-2.5-32b\"),\n",
    "    members=[stock_searcher, company_info_agent],\n",
    "    markdown=True,\n",
    "    \n",
    "    # use_json_mode=True\n",
    ")\n",
    "\n",
    "# This should route to the stock_searcher\n",
    "response = team.print_response(\"What is the current price of NVDIA?\")\n",
    "# assert isinstance(response.content, StockAnalysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a852a122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29ffb5b719f549fdaaaaeb27238ef76c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\documents\\GEN AI\\Agno\\venv\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' \n",
       "(from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct \n",
       "POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. \n",
       "`InferenceClient.chat_completion`). If your use case is not supported, please open an issue in \n",
       "https://github.com/huggingface/huggingface_hub.\n",
       "  warnings.warn(warning_message, FutureWarning)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\documents\\GEN AI\\Agno\\venv\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' \n",
       "(from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct \n",
       "POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. \n",
       "`InferenceClient.chat_completion`). If your use case is not supported, please open an issue in \n",
       "https://github.com/huggingface/huggingface_hub.\n",
       "  warnings.warn(warning_message, FutureWarning)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">ERROR   </span> Error searching for documents: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">503</span> Server Error: Service Temporarily Unavailable for url:                 \n",
       "         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://router.huggingface.co/hf-inference/models/jinaai/jina-embeddings-v2-base-code</span>                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mERROR   \u001b[0m Error searching for documents: \u001b[1;36m503\u001b[0m Server Error: Service Temporarily Unavailable for url:                 \n",
       "         \u001b[4;94mhttps://router.huggingface.co/hf-inference/models/jinaai/jina-embeddings-v2-base-code\u001b[0m                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from agno.agent import Agent, RunResponse\n",
    "from agno.models.groq import Groq\n",
    "from agno.knowledge.pdf import PDFKnowledgeBase, PDFReader\n",
    "from agno.vectordb.chroma import ChromaDb\n",
    "from agno.embedder.huggingface import HuggingfaceCustomEmbedder\n",
    "\n",
    "db_url = \"postgresql://postgres:2404@localhost:5432/sampledatabase\"\n",
    "knowledge_base = PDFKnowledgeBase(\n",
    "    path=\"assets/attention.pdf\",\n",
    "    vector_db=ChromaDb(collection=\"transformer\",embedder=HuggingfaceCustomEmbedder(),persistent_client=True),\n",
    "    reader=PDFReader(chunk=True),\n",
    ")\n",
    "# Load the knowledge base: Comment out after first run\n",
    "\n",
    "\n",
    "agent = Agent(\n",
    "    model=Groq(id=\"qwen-2.5-32b\"),\n",
    "    knowledge=knowledge_base,\n",
    "    instructions=[\"only answer from the knowledge base and if you cant find the answer in the knowledge base then say you dont know the answer or cant find answer\"],\n",
    "    # Add a tool to read chat history.\n",
    "    read_chat_history=True,\n",
    "    show_tool_calls=True,\n",
    "    markdown=True,\n",
    "    # debug_mode=True,\n",
    ")\n",
    "# agent.knowledge.load(recreate=True,upsert=True)\n",
    "agent.print_response(\"why self attention is used?\", stream=False)\n",
    "# agent.print_response(\"What was my last question?\", stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b29f119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> Agentic RAG (Retrieval-Augmented Generation) is an advanced technique that builds upon traditional RAG methods  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> used in large language models (LLMs). Unlike the conventional approach, where information is retrieved once and <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> then used to generate a response, Agentic RAG enables the LLM to act more autonomously. It allows the model to  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> plan, seek additional information iteratively, and make autonomous decisions regarding how to proceed with the  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> retrieval and generation process. Essentially, it endows the LLM with a form of agency, letting it function     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> like an intelligent agent capable of accessing external knowledge and tools, and improving its response over    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> multiple iterations.                                                                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> Here are sources that further explain Agentic RAG:                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><a href=\"https://techcommunity.microsoft.com/blog/educatordeveloperblog/ai-agents-mastering-agentic-rag---part-5/4396171\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; text-decoration: underline\">AI Agents: Mastering Agentic RAG - Part 5</span></a>                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><a href=\"https://weaviate.io/blog/what-is-agentic-rag\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; text-decoration: underline\">What is Agentic RAG</span></a>                                                                                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><a href=\"https://microsoft.github.io/ai-agents-for-beginners/05-agentic-rag/\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; text-decoration: underline\">AI Agents for Beginners: Agentic RAG</span></a>                                                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><a href=\"https://arxiv.org/abs/2501.09136\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; text-decoration: underline\">Agentic Retrieval-Augmented Generation: A Survey on Agentic RAG</span></a>                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><a href=\"https://community.intersystems.com/post/how-build-agentic-ai-rag-application-step-step-guide\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; text-decoration: underline\">Guide to Building an Agentic AI RAG Application</span></a>                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> These resources provide a deeper understanding of how Agentic RAG operates and its benefits over traditional    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> RAG methods.                                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m Agentic RAG (Retrieval-Augmented Generation) is an advanced technique that builds upon traditional RAG methods  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m used in large language models (LLMs). Unlike the conventional approach, where information is retrieved once and \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m then used to generate a response, Agentic RAG enables the LLM to act more autonomously. It allows the model to  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m plan, seek additional information iteratively, and make autonomous decisions regarding how to proceed with the  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m retrieval and generation process. Essentially, it endows the LLM with a form of agency, letting it function     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m like an intelligent agent capable of accessing external knowledge and tools, and improving its response over    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m multiple iterations.                                                                                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m Here are sources that further explain Agentic RAG:                                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;33m • \u001b[0m\u001b]8;id=992205;https://techcommunity.microsoft.com/blog/educatordeveloperblog/ai-agents-mastering-agentic-rag---part-5/4396171\u001b\\\u001b[4;34mAI Agents: Mastering Agentic RAG - Part 5\u001b[0m\u001b]8;;\u001b\\                                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;33m • \u001b[0m\u001b]8;id=239910;https://weaviate.io/blog/what-is-agentic-rag\u001b\\\u001b[4;34mWhat is Agentic RAG\u001b[0m\u001b]8;;\u001b\\                                                                                          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;33m • \u001b[0m\u001b]8;id=359142;https://microsoft.github.io/ai-agents-for-beginners/05-agentic-rag/\u001b\\\u001b[4;34mAI Agents for Beginners: Agentic RAG\u001b[0m\u001b]8;;\u001b\\                                                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;33m • \u001b[0m\u001b]8;id=685603;https://arxiv.org/abs/2501.09136\u001b\\\u001b[4;34mAgentic Retrieval-Augmented Generation: A Survey on Agentic RAG\u001b[0m\u001b]8;;\u001b\\                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;33m • \u001b[0m\u001b]8;id=147082;https://community.intersystems.com/post/how-build-agentic-ai-rag-application-step-step-guide\u001b\\\u001b[4;34mGuide to Building an Agentic AI RAG Application\u001b[0m\u001b]8;;\u001b\\                                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m These resources provide a deeper understanding of how Agentic RAG operates and its benefits over traditional    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m RAG methods.                                                                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Run `pip install duckduckgo-search sqlalchemy openai` to install dependencies.\"\"\"\n",
    "from agno.models.groq import Groq\n",
    "from agno.agent import Agent\n",
    "from agno.storage.sqlite import SqliteStorage\n",
    "from agno.tools.duckduckgo import DuckDuckGoTools\n",
    "from agno.utils.pprint import pprint_run_response\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ['GROQ_API_KEY']=os.getenv('GROQ_API_KEY')\n",
    "agent = Agent(\n",
    "    model=Groq(id=\"qwen-2.5-32b\"),\n",
    "    storage=SqliteStorage(\n",
    "        table_name=\"agent_sessions\", db_file=\"tmp/data.db\", auto_upgrade_schema=True\n",
    "    ),\n",
    "    tools=[DuckDuckGoTools()],\n",
    "    add_history_to_messages=True,\n",
    "    add_datetime_to_instructions=True,\n",
    ")\n",
    "response: RunResponse = agent.run(\"What is Agentic RAG\")\n",
    "# Run agent and return the response as a stream\n",
    "# response_stream: Iterator[RunResponse] = agent.run(\"What is Crew AI\", stream=True)\n",
    "\n",
    "# Print the response in markdown format\n",
    "pprint_run_response(response, markdown=True)\n",
    "# Print the response stream in markdown format\n",
    "# pprint_run_response(response_stream, markdown=True)\n",
    "# agent.print_response(\"What is capital of Canada?\",markdown=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cda4317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> The previous question you asked was about the definition and explanation of \"Agentic RAG.\" You wanted to know   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> what Agentic RAG is, and I provided an explanation along with some sources for further reading.                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m The previous question you asked was about the definition and explanation of \"Agentic RAG.\" You wanted to know   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m what Agentic RAG is, and I provided an explanation along with some sources for further reading.                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "response: RunResponse = agent.run(\"What is the previous question i asked\")\n",
    "pprint_run_response(response, markdown=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84de514",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.print_response(\"List my messages one by one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89283ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=[4, 1, 3, 2, 4, 5, 1, 4]\n",
    "n=len(l)\n",
    "d={}\n",
    "for i in range(n):\n",
    "    if l[i] not in d:\n",
    "        d[l[i]]=1\n",
    "    else:\n",
    "        d[l[i]]+=1\n",
    "max=0\n",
    "ans=0\n",
    "for i,j in d.items():\n",
    "    if max<j:\n",
    "        ans=i\n",
    "        max=j\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43801ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
