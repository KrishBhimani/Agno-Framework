{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd1f448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #5fd7ff; text-decoration-color: #5fd7ff\">INFO</span> Embedder not provided, using OpenAIEmbedder as default.                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;81mINFO\u001b[0m Embedder not provided, using OpenAIEmbedder as default.                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #5fd7ff; text-decoration-color: #5fd7ff\">INFO</span> Creating collection                                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;81mINFO\u001b[0m Creating collection                                                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #5fd7ff; text-decoration-color: #5fd7ff\">INFO</span> Loading knowledge base                                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;81mINFO\u001b[0m Loading knowledge base                                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #5fd7ff; text-decoration-color: #5fd7ff\">INFO</span> Reading: Akreage Launch Pad Whitepaper                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;81mINFO\u001b[0m Reading: Akreage Launch Pad Whitepaper                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #5fd7ff; text-decoration-color: #5fd7ff\">INFO</span> Added <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> documents to knowledge base                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;81mINFO\u001b[0m Added \u001b[1;36m6\u001b[0m documents to knowledge base                                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #5fd7ff; text-decoration-color: #5fd7ff\">INFO</span> Reading: Akreage_Launchpad_Scope_of_Work <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;81mINFO\u001b[0m Reading: Akreage_Launchpad_Scope_of_Work \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #5fd7ff; text-decoration-color: #5fd7ff\">INFO</span> Added <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> documents to knowledge base                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;81mINFO\u001b[0m Added \u001b[1;36m2\u001b[0m documents to knowledge base                                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #5fd7ff; text-decoration-color: #5fd7ff\">INFO</span> Reading: Plan of Action                                                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;81mINFO\u001b[0m Reading: Plan of Action                                                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #5fd7ff; text-decoration-color: #5fd7ff\">INFO</span> Added <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> documents to knowledge base                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;81mINFO\u001b[0m Added \u001b[1;36m5\u001b[0m documents to knowledge base                                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from agno.agent import Agent\n",
    "from agno.team import Team\n",
    "from agno.tools import tool\n",
    "from agno.models.openai import OpenAIChat\n",
    "from agno.knowledge.pdf import PDFKnowledgeBase\n",
    "from agno.vectordb.qdrant import Qdrant\n",
    "from agno.vectordb.search import SearchType\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "# === Tool-Based Agents ===\n",
    "@tool(name=\"clickup_create\", description=\"This tool is used to create a task on ClickUp\", stop_after_tool_call=False)\n",
    "def clickup_create(**kwargs):\n",
    "    \"\"\"\n",
    "    This tool triggers a ClickUp task creation webhook and returns the webhook's response.\n",
    "\n",
    "    Expected kwargs:\n",
    "    - task_name (str) [REQUIRED]: Title of the ClickUp task.\n",
    "    - content (str) [OPTIONAL]: Detailed description of the task.\n",
    "    - assignee (str) [OPTIONAL]: User ID or email of the person to assign the task to.\n",
    "    - priority (str/int) [OPTIONAL]: Task priority (e.g., \"urgent\", \"high\", \"normal\", or number code).\n",
    "    - due_date (str) [OPTIONAL]: Due date in ISO 8601 format (e.g., \"2025-07-31T18:00:00Z\").\n",
    "\n",
    "    The function sends these parameters to a pre-configured webhook and returns its response.\n",
    "    \"\"\"\n",
    "    WEBHOOK_URL = \"https://your-webhook-url.com/clickup/create\"  # replace with your actual URL\n",
    "\n",
    "    try:\n",
    "        response = requests.post(WEBHOOK_URL, json=kwargs, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        return response.json()  # or response.text if your webhook returns plain text\n",
    "    except requests.RequestException as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "clickup_agent = Agent(\n",
    "    name=\"ClickUp Agent\",\n",
    "    model=OpenAIChat(id=\"gpt-4.1-nano\"),\n",
    "    tools=[clickup_create,clickup_update, clickup_get],\n",
    "    show_tool_calls=True,\n",
    "    read_chat_history=True,\n",
    "    instructions=[\"Only respond to ClickUp-related tasks like creating, updating, or assigning tasks.\"]\n",
    ")\n",
    "\n",
    "@tool(name=\"slack_tool\", stop_after_tool_call=False)\n",
    "def slack_tool(**kwargs):\n",
    "    return \"‚úÖ Slack tool triggered\"\n",
    "\n",
    "slack_agent = Agent(\n",
    "    name=\"Slack Agent\",\n",
    "    model=OpenAIChat(id=\"gpt-4.1-nano\"),\n",
    "    tools=[slack_tool],\n",
    "    show_tool_calls=True,\n",
    "    read_chat_history=True,\n",
    "    instructions=[\"Handle Slack messaging, tagging, and notifications.\"]\n",
    ")\n",
    "\n",
    "@tool(name=\"github_tool\", stop_after_tool_call=False )\n",
    "def github_tool(**kwargs):\n",
    "    return \"‚úÖ GitHub tool triggered\"\n",
    "\n",
    "github_agent = Agent(\n",
    "    name=\"GitHub Agent\",\n",
    "    model=OpenAIChat(id=\"gpt-4.1-nano\"),\n",
    "    tools=[github_tool],\n",
    "    show_tool_calls=True,\n",
    "    read_chat_history=True,\n",
    "    instructions=[\"Respond to GitHub requests like creating issues, reviewing PRs, or commenting.\"]\n",
    ")\n",
    "\n",
    "@tool(name=\"devin_tool\", stop_after_tool_call=False )\n",
    "def devin_tool(**kwargs):\n",
    "    return \"‚úÖ Devin tool triggered\"\n",
    "\n",
    "devin_agent = Agent(\n",
    "    name=\"Devin Agent\",\n",
    "    model=OpenAIChat(id=\"gpt-4.1-nano\"),\n",
    "    tools=[devin_tool],\n",
    "    show_tool_calls=True,\n",
    "    read_chat_history=True,\n",
    "    instructions=[\"Handle developer tasks like debugging, running tests, or building workflows.\"]\n",
    ")\n",
    "\n",
    "# === RAG Agent ===\n",
    "\n",
    "collection_name = \"new\"\n",
    "qdrant_url = \"http://localhost:6333\"\n",
    "\n",
    "knowledge_base = PDFKnowledgeBase(\n",
    "                path=f\"data/user_abc\",\n",
    "                vector_db=Qdrant(\n",
    "                    collection=collection_name,\n",
    "                    url=qdrant_url,\n",
    "                    # search_type=SearchType.hybrid,\n",
    "                ),\n",
    "            )\n",
    "\n",
    "rag_agent = Agent(\n",
    "    name=\"Knowledge Agent\",\n",
    "    model=OpenAIChat(id=\"gpt-4.1-nano\"),\n",
    "    knowledge=knowledge_base,\n",
    "    search_knowledge=True,\n",
    "    read_chat_history=True,\n",
    "    instructions=[\n",
    "            \"You are a helpful assistant that can answer questions based on the provided PDF documents.\",\n",
    "            \"Always cite the source when providing information from the documents.\",\n",
    "            \"If you cannot find the answer in the documents, clearly state that.\",\n",
    "            \"Be concise but thorough in your responses.\",\n",
    "            \"Cite sources when possible. If nothing is found, say so clearly.\"\n",
    "        ],\n",
    ")\n",
    "# === Orchestrator Team ===\n",
    "\n",
    "orchestrator = Team(\n",
    "    name=\"XO Orchestrator\",\n",
    "    model=OpenAIChat(id=\"gpt-4o\"),\n",
    "    members=[\n",
    "        rag_agent,\n",
    "        clickup_agent,\n",
    "        slack_agent,\n",
    "        github_agent,\n",
    "        devin_agent\n",
    "    ],\n",
    "    instructions = [\n",
    "                        \"You are the coordinator for a team of specialized agents, each responsible for handling a specific type of request.\",\n",
    "                        \n",
    "                        \"You must determine which agent to delegate a user message to, based on the presence of explicit `@mentions`.\",\n",
    "                        \n",
    "                        \"Only trigger a specialized tool agent if the message includes one of the exact @mentions listed below. \"\n",
    "                        \"If no such @mention is present, route the message to the `rag_agent` by default.\",\n",
    "                        \n",
    "                        \"Agent routing rules:\",\n",
    "                        \"- Route to `clickup_agent` only if the message contains `@click-up`.\",\n",
    "                        \"- Route to `slack_agent` only if the message contains `@slack`.\",\n",
    "                        \"- Route to `github_agent` only if the message contains `@github`.\",\n",
    "                        \"- Route to `copilot_agent` only if the message contains `@github-copilot`.\",\n",
    "                        \"- Route to `devin_agent` only if the message contains `@devin`.\",\n",
    "                        \"- Always route to `rag_agent` if the message contains `@XO`, or if no @mention is present at all.\",\n",
    "                        \n",
    "                        \"Do not infer tool usage from intent or keywords alone. If a message talks about GitHub or Slack but does not include the corresponding @mention, it should go to the `rag_agent`.\",\n",
    "                        \n",
    "                        \"If the message is ambiguous, vague, or lacking required context, delegate to the `rag_agent` and allow it to respond or request clarification.\",\n",
    "                        \n",
    "                        \"Your role is strictly to select the correct agent for execution. You do not generate or modify responses yourself.\"\n",
    "                    ],\n",
    "    mode=\"route\",\n",
    "    share_member_interactions=True,\n",
    "    show_members_responses=True,\n",
    "    read_team_history=True,\n",
    "    enable_agentic_context=True,\n",
    "    enable_team_history=True,\n",
    "    num_of_interactions_from_history=5,\n",
    "    show_tool_calls=True,\n",
    ")\n",
    "knowledge_base.load(recreate=False)\n",
    "\n",
    "# === Example Usage ===\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     response = orchestrator.run(\"Update the ClickUp task to fix the login bug and notify @krish on Slack.\")\n",
    "#     print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "647adb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† XO Orchestrator is ready. Type 'exit' to quit.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d88e3fdfcfa94b198b271eeb9d133f1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a324bf07ce4d02b51bd84f2eac110d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c07ca2fd5c5458da4cdeb4c63141746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëã Goodbye!\n"
     ]
    }
   ],
   "source": [
    "def chat_with_orchestrator(agent):\n",
    "    print(\"üß† XO Orchestrator is ready. Type 'exit' to quit.\\n\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \").strip()\n",
    "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "            print(\"üëã Goodbye!\")\n",
    "            break\n",
    "        try:\n",
    "            agent.print_response(user_input,stream=True)\n",
    "            # response = agent.run(user_input)\n",
    "            # print(f\"üß† XO: {response.content}\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\\n\")\n",
    "if __name__ == \"__main__\":\n",
    "    chat_with_orchestrator(orchestrator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7da433ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Embedder not provided, using OpenAIEmbedder as default.                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Embedder not provided, using OpenAIEmbedder as default.                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Loading knowledge base                                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Loading knowledge base                                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Reading: leac203                                                                                              \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Reading: leac203                                                                                              \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Added <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> documents to knowledge base                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Added \u001b[1;36m0\u001b[0m documents to knowledge base                                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from agno.agent import Agent\n",
    "from agno.models.openai import OpenAIChat\n",
    "from agno.storage.sqlite import SqliteStorage\n",
    "from agno.models.openai import OpenAIChat\n",
    "from agno.knowledge.pdf import PDFKnowledgeBase\n",
    "from agno.vectordb.qdrant import Qdrant\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "user_id=\"user_finance2\"\n",
    "collection_name = \"user_finance\"\n",
    "qdrant_url = \"http://localhost:6333\"\n",
    "sql_db=SqliteStorage(table_name=\"agent_sessions\", db_file=\"tmp/data.db\")\n",
    "knowledge_base = PDFKnowledgeBase(\n",
    "                path=f\"data/user_finance\",\n",
    "                vector_db=Qdrant(\n",
    "                    collection=collection_name,\n",
    "                    url=qdrant_url,\n",
    "                    # search_type=SearchType.hybrid,\n",
    "                ),\n",
    "            )\n",
    "\n",
    "rag_agent = Agent(\n",
    "    name=\"Knowledge Agent\",\n",
    "    model=OpenAIChat(id=\"gpt-4.1-nano\"),\n",
    "    knowledge=knowledge_base,\n",
    "    storage=storage,\n",
    "    session_id=user_id,\n",
    "    search_knowledge=True,\n",
    "    read_chat_history=True,\n",
    "    add_history_to_messages=True,\n",
    "    # instructions=[\n",
    "    #         \"You are a helpful assistant that can answer questions based on the provided PDF documents.\",\n",
    "    #         \"Always cite the source when providing information from the documents.\",\n",
    "    #         \"If you cannot find the answer in the documents, clearly state that.\",\n",
    "    #         \"Be concise but thorough in your responses.\",\n",
    "    #         \"Cite sources when possible. If nothing is found, say so clearly.\"\n",
    "    #     ],\n",
    "    instructions = [\n",
    "                    \"You are a helpful assistant that answers questions using only the content from the provided PDF documents.\",\n",
    "                    \"Do not guess or hallucinate. If the answer is not explicitly or implicitly found in the documents, respond with 'The answer is not available in the provided documents.'\",\n",
    "                    \"Always include an in-text citation indicating the source document and relevant section (e.g., page number or heading) when referencing information.\",\n",
    "                    \"Be concise, accurate, and informative. Avoid unnecessary elaboration not supported by the documents.\",\n",
    "                    \"Use clear and professional language appropriate for academic or business use.\",\n",
    "                    \"Do not include external knowledge or personal opinions. Only rely on the content available in the documents.\",\n",
    "                    \"Structure multi-point answers in bullet or numbered format where applicable for better readability.\"\n",
    "                ],\n",
    ")\n",
    "\n",
    "clickup_agent = Agent(\n",
    "    name=\"ClickUp Agent\",\n",
    "    model=OpenAIChat(id=\"gpt-4.1-nano\"),\n",
    "    show_tool_calls=True,\n",
    "    storage=storage,\n",
    "    session_id=user_id,\n",
    "    read_chat_history=True,\n",
    "    add_history_to_messages=True,\n",
    "    instructions=[\"create a format of clickup task based on the emory and user query, if its create task, the output a json containing task title, description, and due date\",\n",
    "                  \"if the task is to update then output the fields to edit\",\n",
    "                  \"if the task is to get task then output the title\"]\n",
    ")\n",
    "\n",
    "slack_agent = Agent(\n",
    "    name=\"Slack Agent\",\n",
    "    model=OpenAIChat(id=\"gpt-4.1-nano\"),\n",
    "    show_tool_calls=True,\n",
    "    storage=storage,\n",
    "    session_id=user_id,\n",
    "    read_chat_history=True,\n",
    "    add_history_to_messages=True,\n",
    "    instructions=[\"Handle Slack messaging, tagging, and notifications.\"]\n",
    ")\n",
    "agent=Agent(\n",
    "    name=\"Agent\",\n",
    "    model=OpenAIChat(id=\"gpt-4.1-nano\"),\n",
    "    show_tool_calls=True,\n",
    "    storage=storage,\n",
    "    session_id=user_id,\n",
    "    read_chat_history=True,\n",
    "    add_history_to_messages=True,\n",
    "    instructions=[\"Handle general conversational queries\"]\n",
    ")\n",
    "knowledge_base.load(recreate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438eb57b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6acc84cdd8a84acc8294733aa54984a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "rag_agent.print_response(\"\",stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fec3332d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9316fa73f984582aabc2efc51dc8139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clickup_agent.print_response(\"what are all the questions/input i have asked till now\",stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c890f698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2783028558cf4926900b5c672672d041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "slack_agent.print_response(\"what do i do at XO\",stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd9590e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a4ed0921e146d4beb85ce3eaac0d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent.print_response(\"\",stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5e597c06",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ToolExecution' from 'agno.models.response' (c:\\documents\\GEN AI\\Agno\\venv\\Lib\\site-packages\\agno\\models\\response.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[109]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magno\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01magent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Agent\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magno\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmemory\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msqlite\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SqliteMemoryDb\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magno\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmemory\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmemory\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Memory\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magno\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAIChat\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magno\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstorage\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msqlite\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SqliteStorage\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\documents\\GEN AI\\Agno\\venv\\Lib\\site-packages\\agno\\memory\\v2\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magno\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmemory\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmemory\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Memory, MemoryManager, MemoryRow, SessionSummarizer\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magno\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmemory\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mschema\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SessionSummary, UserMemory\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\documents\\GEN AI\\Agno\\venv\\Lib\\site-packages\\agno\\memory\\v2\\memory.py:18\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magno\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magno\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmessage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Message\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magno\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrun\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RunStatus\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magno\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrun\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mresponse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RunResponse\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magno\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrun\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mteam\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TeamRunResponse\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\documents\\GEN AI\\Agno\\venv\\Lib\\site-packages\\agno\\run\\base.py:9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magno\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmedia\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AudioArtifact, AudioResponse, ImageArtifact, VideoArtifact\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magno\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmessage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Citations, Message, MessageReferences\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magno\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mresponse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ToolExecution\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magno\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreasoning\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstep\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ReasoningStep\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magno\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlog\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m log_error\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'ToolExecution' from 'agno.models.response' (c:\\documents\\GEN AI\\Agno\\venv\\Lib\\site-packages\\agno\\models\\response.py)"
     ]
    }
   ],
   "source": [
    "from agno.agent import Agent\n",
    "from agno.memory.v2.db.sqlite import SqliteMemoryDb\n",
    "from agno.memory.v2.memory import Memory\n",
    "from agno.models.openai import OpenAIChat\n",
    "from agno.storage.sqlite import SqliteStorage\n",
    "from rich.pretty import pprint\n",
    "# UserId for the memories\n",
    "user_id = \"ava\"\n",
    "# Database file for memory and storage\n",
    "db_file = \"tmp/agent.db\"\n",
    "\n",
    "# Initialize memory.v2\n",
    "memory = Memory(\n",
    "    # Use any model for creating memories\n",
    "    model=OpenAIChat(id=\"gpt-4.1\"),\n",
    "    db=SqliteMemoryDb(table_name=\"user_memories\", db_file=db_file),\n",
    ")\n",
    "# Initialize storage\n",
    "storage = SqliteStorage(table_name=\"agent_sessions\", db_file=db_file)\n",
    "\n",
    "# Initialize Agent\n",
    "memory_agent = Agent(\n",
    "    model=OpenAIChat(id=\"gpt-4.1\"),\n",
    "    # Store memories in a database\n",
    "    memory=memory,\n",
    "    # Give the Agent the ability to update memories\n",
    "    enable_agentic_memory=True,\n",
    "    # OR - Run the MemoryManager after each response\n",
    "    enable_user_memories=True,\n",
    "    # Store the chat history in the database\n",
    "    storage=storage,\n",
    "    # Add the chat history to the messages\n",
    "    add_history_to_messages=True,\n",
    "    # Number of history runs\n",
    "    num_history_runs=3,\n",
    "    markdown=True,\n",
    ")\n",
    "\n",
    "memory.clear()\n",
    "memory_agent.print_response(\n",
    "    \"My name is Ava and I like to ski.\",\n",
    "    user_id=user_id,\n",
    "    stream=True,\n",
    "    stream_intermediate_steps=True,\n",
    ")\n",
    "print(\"Memories about Ava:\")\n",
    "pprint(memory.get_user_memories(user_id=user_id))\n",
    "\n",
    "memory_agent.print_response(\n",
    "    \"I live in san francisco, where should i move within a 4 hour drive?\",\n",
    "    user_id=user_id,\n",
    "    stream=True,\n",
    "    stream_intermediate_steps=True,\n",
    ")\n",
    "print(\"Memories about Ava:\")\n",
    "pprint(memory.get_user_memories(user_id=user_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "169ebcd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d26e7e58c8c4ad4ad1c1046c76dd866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent.print_response(\"help me ideate a draft for a github issue to fix the background issue, create title and its content\",stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d65a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd3c67683fc44054b12a1e8096c1a2bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent1 = Agent(storage=storage,session_id=\"User1\",read_chat_history=True,)\n",
    "agent1.print_response(\"What is my name\",stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "47f1251d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17a08e4eba3c40a2951a3fc0d715251f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent1.print_response(\"Mention details you know about me\",stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5d1c35ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent2 = Agent(storage=storage,session_id=\"User1\",read_chat_history=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8d858703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5dc9b99c1c44d1a8728274e87101a1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent2.print_response(\"What is my name\",stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb14ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
