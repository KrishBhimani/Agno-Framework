{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f9e394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "from typing import List\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance, PointStruct\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import openai\n",
    "from agno.agent import Agent\n",
    "from agno.vectordb.qdrant import Qdrant as AgnoQdrant\n",
    "from agno.knowledge import AgentKnowledge\n",
    "from agno.embedder.openai import OpenAIEmbedder\n",
    "from langchain_core.messages import HumanMessage\n",
    "from agno.document.chunking.document import DocumentChunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df5d2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from agno.agent import Agent\n",
    "from agno.knowledge.pdf_url import PDFUrlKnowledgeBase\n",
    "from agno.vectordb.qdrant import Qdrant\n",
    "\n",
    "COLLECTION_NAME = \"Akreage\"\n",
    "\n",
    "# Initialize Qdrant with local instance\n",
    "vector_db = Qdrant(\n",
    "    collection=COLLECTION_NAME, \n",
    "    url=\"http://localhost:6333\"\n",
    ")\n",
    "\n",
    "# Create knowledge base\n",
    "knowledge_base = PDFUrlKnowledgeBase(\n",
    "    urls=[\"https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\"],\n",
    "    vector_db=vector_db,\n",
    ")\n",
    "\n",
    "agent = Agent(knowledge=knowledge_base, show_tool_calls=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load knowledge base asynchronously\n",
    "    asyncio.run(knowledge_base.aload(recreate=False))  # Comment out after first run\n",
    "\n",
    "    # Create and use the agent asynchronously\n",
    "    asyncio.run(agent.aprint_response(\"How to make Tom Kha Gai\", markdown=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7165aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Multi-PDF Qdrant Agent setup...\n",
      "Setting up Qdrant vector database...\n",
      "‚úì Qdrant vector database initialized with collection: my_documents\n",
      "Setting up knowledge base from 3 PDF files...\n",
      "Processing PDF 1/3: Akreage Launch Pad Whitepaper.pdf\n",
      "Processing PDF 2/3: Akreage_Launchpad_Scope_of_Work (1).pdf\n",
      "Processing PDF 3/3: Plan of Action .pdf\n",
      "‚úì Knowledge base created successfully\n",
      "Loading knowledge base and creating embeddings...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Loading knowledge base                                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Loading knowledge base                                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Reading: Akreage Launch Pad Whitepaper                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Reading: Akreage Launch Pad Whitepaper                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Added <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> documents to knowledge base                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Added \u001b[1;36m0\u001b[0m documents to knowledge base                                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Reading: Akreage_Launchpad_Scope_of_Work <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Reading: Akreage_Launchpad_Scope_of_Work \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Added <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> documents to knowledge base                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Added \u001b[1;36m0\u001b[0m documents to knowledge base                                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Reading: Plan of Action                                                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Reading: Plan of Action                                                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Added <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> documents to knowledge base                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Added \u001b[1;36m0\u001b[0m documents to knowledge base                                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Knowledge base loaded and embeddings created\n",
      "Setting up agent...\n",
      "‚úì Agent initialized successfully\n",
      "üéâ Multi-PDF Qdrant Agent setup complete!\n",
      "\n",
      "üìä Collection Info:\n",
      "  collection_name: my_documents\n",
      "  qdrant_url: http://localhost:6333\n",
      "  pdf_count: 3\n",
      "  pdf_files: ['Akreage Launch Pad Whitepaper.pdf', 'Akreage_Launchpad_Scope_of_Work (1).pdf', 'Plan of Action .pdf']\n",
      "\n",
      "üîç Example Queries:\n",
      "  - What are the main topics covered in these documents?\n",
      "  - Can you summarize the key points from all the documents?\n",
      "  - What specific information is available about [your topic]?\n",
      "\n",
      "ü§ñ Interactive Chat Started!\n",
      "Type 'quit', 'exit', or 'bye' to end the session.\n",
      "==================================================\n",
      "\n",
      "ü§î Question: what is Akreage\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e1461a7832c4071abf819629c967255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§î Question: what is the plan of action\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6faadaae0c4b42458ee1c7f996cb5d65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëã Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List, Union\n",
    "from pathlib import Path\n",
    "\n",
    "from agno.agent import Agent\n",
    "from agno.knowledge.pdf import PDFKnowledgeBase\n",
    "from agno.knowledge.combined import CombinedKnowledgeBase\n",
    "from agno.vectordb.qdrant import Qdrant\n",
    "from agno.models.openai import OpenAIChat\n",
    "from agno.embedder.openai import OpenAIEmbedder\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv('OPENAI_API_KEY')\n",
    "class MultiPDFQdrantAgent:\n",
    "    \"\"\"\n",
    "    A class to handle multiple PDF files, embed them in Qdrant vector database,\n",
    "    and provide an interactive agent interface.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        pdf_paths: List[Union[str, Path]],\n",
    "        collection_name: str = \"multi_pdf_collection\",\n",
    "        qdrant_url: str = \"http://localhost:6333\",\n",
    "        model_name: str = \"gpt-4o-mini\",\n",
    "        embedding_model: str = \"text-embedding-3-small\"\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the Multi-PDF Qdrant Agent.\n",
    "        \n",
    "        Args:\n",
    "            pdf_paths: List of paths to PDF files\n",
    "            collection_name: Name of the Qdrant collection\n",
    "            qdrant_url: URL of the Qdrant instance\n",
    "            model_name: OpenAI model name for the agent\n",
    "            embedding_model: OpenAI embedding model name\n",
    "        \"\"\"\n",
    "        self.pdf_paths = [Path(path) for path in pdf_paths]\n",
    "        self.collection_name = collection_name\n",
    "        self.qdrant_url = qdrant_url\n",
    "        self.model_name = model_name\n",
    "        self.embedding_model = embedding_model\n",
    "        \n",
    "        # Validate PDF paths\n",
    "        self._validate_pdf_paths()\n",
    "        \n",
    "        # Initialize components\n",
    "        self.vector_db = None\n",
    "        self.knowledge_base = None\n",
    "        self.agent = None\n",
    "        \n",
    "    def _validate_pdf_paths(self):\n",
    "        \"\"\"Validate that all PDF paths exist and are PDF files.\"\"\"\n",
    "        for pdf_path in self.pdf_paths:\n",
    "            if not pdf_path.exists():\n",
    "                raise FileNotFoundError(f\"PDF file not found: {pdf_path}\")\n",
    "            if pdf_path.suffix.lower() != '.pdf':\n",
    "                raise ValueError(f\"File is not a PDF: {pdf_path}\")\n",
    "    \n",
    "    def _setup_vector_db(self):\n",
    "        \"\"\"Initialize the Qdrant vector database.\"\"\"\n",
    "        print(f\"Setting up Qdrant vector database...\")\n",
    "        self.vector_db = Qdrant(\n",
    "            collection=self.collection_name,\n",
    "            url=self.qdrant_url,\n",
    "            embedder=OpenAIEmbedder()\n",
    "        )\n",
    "        print(f\"‚úì Qdrant vector database initialized with collection: {self.collection_name}\")\n",
    "    \n",
    "    def _setup_knowledge_base(self):\n",
    "        \"\"\"Create knowledge base from multiple PDF files.\"\"\"\n",
    "        print(f\"Setting up knowledge base from {len(self.pdf_paths)} PDF files...\")\n",
    "        \n",
    "        knowledge_bases = []\n",
    "        \n",
    "        for i, pdf_path in enumerate(self.pdf_paths):\n",
    "            print(f\"Processing PDF {i+1}/{len(self.pdf_paths)}: {pdf_path.name}\")\n",
    "            \n",
    "            # Create individual knowledge base for each PDF\n",
    "            pdf_kb = PDFKnowledgeBase(\n",
    "                path=str(pdf_path),\n",
    "                vector_db=self.vector_db,\n",
    "                # Optional: Add custom reader settings\n",
    "                # reader=PDFReader(chunk_size=3000, chunk_overlap=200)\n",
    "            )\n",
    "            knowledge_bases.append(pdf_kb)\n",
    "        \n",
    "        # Combine all knowledge bases if multiple PDFs\n",
    "        if len(knowledge_bases) == 1:\n",
    "            self.knowledge_base = knowledge_bases[0]\n",
    "        else:\n",
    "            self.knowledge_base = CombinedKnowledgeBase(\n",
    "                sources=knowledge_bases,\n",
    "                vector_db=self.vector_db\n",
    "            )\n",
    "        \n",
    "        print(\"‚úì Knowledge base created successfully\")\n",
    "    \n",
    "    def _setup_agent(self):\n",
    "        \"\"\"Initialize the agent with the knowledge base.\"\"\"\n",
    "        print(\"Setting up agent...\")\n",
    "        self.agent = Agent(\n",
    "            model=OpenAIChat(id=self.model_name),\n",
    "            knowledge=self.knowledge_base,\n",
    "            show_tool_calls=True,\n",
    "            instructions=[\n",
    "                \"You are a helpful assistant that can answer questions based on the provided PDF documents.\",\n",
    "                \"Always cite the source when providing information from the documents.\",\n",
    "                \"If you cannot find the answer in the documents, clearly state that.\",\n",
    "                \"Be concise but thorough in your responses.\"\n",
    "            ]\n",
    "        )\n",
    "        print(\"‚úì Agent initialized successfully\")\n",
    "    \n",
    "    def setup(self, recreate_embeddings: bool = False):\n",
    "        \"\"\"\n",
    "        Setup the complete system: vector DB, knowledge base, and agent.\n",
    "        \n",
    "        Args:\n",
    "            recreate_embeddings: If True, recreate embeddings even if they exist\n",
    "        \"\"\"\n",
    "        print(\"Starting Multi-PDF Qdrant Agent setup...\")\n",
    "        \n",
    "        # Setup vector database\n",
    "        self._setup_vector_db()\n",
    "        \n",
    "        # Setup knowledge base\n",
    "        self._setup_knowledge_base()\n",
    "        \n",
    "        # Load knowledge base (create embeddings)\n",
    "        print(\"Loading knowledge base and creating embeddings...\")\n",
    "        self.knowledge_base.load(recreate=recreate_embeddings)\n",
    "        print(\"‚úì Knowledge base loaded and embeddings created\")\n",
    "        \n",
    "        # Setup agent\n",
    "        self._setup_agent()\n",
    "        \n",
    "        print(\"üéâ Multi-PDF Qdrant Agent setup complete!\")\n",
    "    \n",
    "    def query(self, question: str, markdown: bool = True) -> str:\n",
    "        \"\"\"\n",
    "        Query the agent with a question.\n",
    "        \n",
    "        Args:\n",
    "            question: The question to ask\n",
    "            markdown: Whether to format response as markdown\n",
    "            \n",
    "        Returns:\n",
    "            The agent's response\n",
    "        \"\"\"\n",
    "        if self.agent is None:\n",
    "            raise RuntimeError(\"Agent not initialized. Call setup() first.\")\n",
    "        \n",
    "        print(f\"\\nü§î Question: {question}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        response = self.agent.print_response(question, markdown=markdown)\n",
    "        return response\n",
    "    \n",
    "    def interactive_chat(self):\n",
    "        \"\"\"Start an interactive chat session.\"\"\"\n",
    "        if self.agent is None:\n",
    "            raise RuntimeError(\"Agent not initialized. Call setup() first.\")\n",
    "        \n",
    "        print(\"\\nü§ñ Interactive Chat Started!\")\n",
    "        print(\"Type 'quit', 'exit', or 'bye' to end the session.\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                question = input(\"\\nüí¨ You: \").strip()\n",
    "                \n",
    "                if question.lower() in ['quit', 'exit', 'bye']:\n",
    "                    print(\"üëã Goodbye!\")\n",
    "                    break\n",
    "                \n",
    "                if not question:\n",
    "                    continue\n",
    "                \n",
    "                self.query(question)\n",
    "                \n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\nüëã Goodbye!\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error: {e}\")\n",
    "    \n",
    "    def get_collection_info(self):\n",
    "        \"\"\"Get information about the Qdrant collection.\"\"\"\n",
    "        if self.vector_db is None:\n",
    "            return \"Vector database not initialized\"\n",
    "        \n",
    "        return {\n",
    "            \"collection_name\": self.collection_name,\n",
    "            \"qdrant_url\": self.qdrant_url,\n",
    "            \"pdf_count\": len(self.pdf_paths),\n",
    "            \"pdf_files\": [p.name for p in self.pdf_paths]\n",
    "        }\n",
    "\n",
    "\n",
    "# Example usage and main function\n",
    "def main():\n",
    "    \"\"\"Example usage of the Multi-PDF Qdrant Agent.\"\"\"\n",
    "    \n",
    "    # List of PDF paths to process\n",
    "    pdf_paths = [\n",
    "        \"C:\\documents\\GEN AI\\Agno\\Agno-Framework\\XO-testing\\Akreage Launch Pad Whitepaper.pdf\",\n",
    "        \"C:\\documents\\GEN AI\\Agno\\Agno-Framework\\XO-testing\\Akreage_Launchpad_Scope_of_Work (1).pdf\",\n",
    "        \"C:\\documents\\GEN AI\\Agno\\Agno-Framework\\XO-testing\\Plan of Action .pdf\",\n",
    "        # Add more PDF paths as needed\n",
    "    ]\n",
    "    \n",
    "    # Create the agent\n",
    "    agent = MultiPDFQdrantAgent(\n",
    "        pdf_paths=pdf_paths,\n",
    "        collection_name=\"my_documents\",\n",
    "        qdrant_url=\"http://localhost:6333\",  # Make sure Qdrant is running\n",
    "        model_name=\"gpt-4o-mini\",\n",
    "        embedding_model=\"text-embedding-3-small\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Setup the agent (this will create embeddings)\n",
    "        agent.setup(recreate_embeddings=False)  # Set to True to recreate embeddings\n",
    "        \n",
    "        # Print collection info\n",
    "        print(\"\\nüìä Collection Info:\")\n",
    "        info = agent.get_collection_info()\n",
    "        for key, value in info.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "        \n",
    "        # Example queries\n",
    "        example_queries = [\n",
    "            \"What are the main topics covered in these documents?\",\n",
    "            \"Can you summarize the key points from all the documents?\",\n",
    "            \"What specific information is available about [your topic]?\"\n",
    "        ]\n",
    "        \n",
    "        print(\"\\nüîç Example Queries:\")\n",
    "        for query in example_queries:\n",
    "            print(f\"  - {query}\")\n",
    "        \n",
    "        # Start interactive chat\n",
    "        agent.interactive_chat()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        print(\"Make sure:\")\n",
    "        print(\"1. Qdrant is running on http://localhost:6333\")\n",
    "        print(\"2. OpenAI API key is set in environment variables\")\n",
    "        print(\"3. All PDF paths are valid\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set your OpenAI API key\n",
    "    # os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\"\n",
    "    \n",
    "    # Run the main function\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc0bb795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Embedder not provided, using OpenAIEmbedder as default.                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Embedder not provided, using OpenAIEmbedder as default.                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Creating collection                                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Creating collection                                                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Loading knowledge base                                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Loading knowledge base                                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Reading: Akreage Launch Pad Whitepaper                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Reading: Akreage Launch Pad Whitepaper                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Added <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> documents to knowledge base                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Added \u001b[1;36m6\u001b[0m documents to knowledge base                                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Reading: Akreage_Launchpad_Scope_of_Work <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Reading: Akreage_Launchpad_Scope_of_Work \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Added <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> documents to knowledge base                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Added \u001b[1;36m2\u001b[0m documents to knowledge base                                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Reading: Introduction                                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Reading: Introduction                                                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Added <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span> documents to knowledge base                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Added \u001b[1;36m19\u001b[0m documents to knowledge base                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Reading: Plan of Action                                                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Reading: Plan of Action                                                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Added <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> documents to knowledge base                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Added \u001b[1;36m5\u001b[0m documents to knowledge base                                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from agno.agent import Agent\n",
    "from agno.knowledge.pdf import PDFKnowledgeBase, PDFReader\n",
    "from agno.vectordb.qdrant import Qdrant\n",
    "from agno.document.chunking.agentic import AgenticChunking\n",
    "# from agno.embedder.sentence_transformer import SentenceTransformerEmbedder\n",
    "from agno.models.openai import OpenAIChat\n",
    "from agno.document.chunking.recursive import RecursiveChunking\n",
    "\n",
    "COLLECTION_NAME = \"multipleDocuments\"\n",
    "\n",
    "vector_db = Qdrant(collection=COLLECTION_NAME, url=\"http://localhost:6333\",\n",
    "\n",
    ")\n",
    "\n",
    "# Create a knowledge base with the PDFs from the data/pdfs directory\n",
    "knowledge_base = PDFKnowledgeBase(\n",
    "    path=\"data/\",\n",
    "    vector_db=vector_db,\n",
    "    reader=PDFReader(chunk=True),\n",
    "    chunking_strategy=RecursiveChunking(chunk_size=5000,overlap=500),\n",
    ")\n",
    "\n",
    "# Create an agent with the knowledge base\n",
    "agent = Agent(\n",
    "    model=OpenAIChat(id=\"gpt-4.1-nano\"),\n",
    "    knowledge=knowledge_base,\n",
    "    search_knowledge=True,\n",
    "    instructions=[\n",
    "                \"You are a helpful assistant that can answer questions based on the provided PDF documents.\",\n",
    "                \"Always cite the source when providing information from the documents.\",\n",
    "                \"If you cannot find the answer in the documents, clearly state that.\",\n",
    "                \"Be concise but thorough in your responses.\"\n",
    "            ]\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Comment out after first run\n",
    "    \n",
    "    knowledge_base.load(recreate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "551bf854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv('OPENAI_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fab78f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LATs tree search is a research framework that combines classical AI search methods, specifically Monte Carlo Tree Search (MCTS), with Large Language Model (LLM)-based reasoning. The core idea is for the agent to explore multiple potential action sequences in a tree structure rather than following a single linear thought process. At each decision point, LATs simulates various \"what if\" scenarios using the LLM to predict outcomes, evaluates these branches, and then selects the most promising one to execute. It also incorporates reflection at each node to identify and correct errors or improve reasoning, making it a powerful approach for complex reasoning problems. This method was reported to outperform simpler agents in challenging tasks such as math or coding problems, but it is resource-intensive due to the multiple LLM calls involved (source: knowledge base, pages 9 and 19).'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "agent.run(\"whats LATs tree search\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28cec26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agno.agent import Agent\n",
    "from agno.knowledge.pdf import PDFKnowledgeBase, PDFReader\n",
    "from agno.vectordb.qdrant import Qdrant\n",
    "from agno.document.chunking.recursive import RecursiveChunking\n",
    "from agno.models.openai import OpenAIChat\n",
    "from pathlib import Path\n",
    "from agno.knowledge import AgentKnowledge\n",
    "from agno.embedder.openai import OpenAIEmbedder\n",
    "\n",
    "def create_user_agent(user_id: str, user_pdf_dir: str):\n",
    "    vector_db = Qdrant(\n",
    "        collection=\"shared_pdf_index\",  # Shared collection\n",
    "        url=\"http://localhost:6333\"\n",
    "    )\n",
    "\n",
    "    knowledge_base = PDFKnowledgeBase(\n",
    "        path=user_pdf_dir,\n",
    "        vector_db=vector_db,\n",
    "        reader=PDFReader(chunk=True),\n",
    "        # chunking_strategy=RecursiveChunking(chunk_size=800, overlap=100),\n",
    "        metadata={\"user_id\": user_id}  # chunks tagged during ingestion\n",
    "    )\n",
    "\n",
    "    agent = Agent(\n",
    "        model=OpenAIChat(id=\"gpt-4.1-nano\"),  # fast model\n",
    "        knowledge=knowledge_base,\n",
    "        search_knowledge=True,\n",
    "        user_id=user_id,\n",
    "        instructions=[\n",
    "            \"You are a helpful assistant that can answer questions based on the provided PDF documents.\",\n",
    "            \"Always cite the source when providing information from the documents.\",\n",
    "            \"If you cannot find the answer in the documents, clearly state that.\",\n",
    "            \"Be concise but thorough in your responses.\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return agent, knowledge_base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "560d0f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Embedder not provided, using OpenAIEmbedder as default.                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Embedder not provided, using OpenAIEmbedder as default.                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Loading knowledge base                                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Loading knowledge base                                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Reading: Akreage Launch Pad Whitepaper                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Reading: Akreage Launch Pad Whitepaper                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Added <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> documents to knowledge base                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Added \u001b[1;36m6\u001b[0m documents to knowledge base                                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Reading: Akreage_Launchpad_Scope_of_Work <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Reading: Akreage_Launchpad_Scope_of_Work \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Added <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> documents to knowledge base                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Added \u001b[1;36m2\u001b[0m documents to knowledge base                                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Reading: Plan of Action                                                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Reading: Plan of Action                                                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Added <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> documents to knowledge base                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Added \u001b[1;36m5\u001b[0m documents to knowledge base                                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ The plan for Week 1 involves finalizing the requirements and preparing the technical groundwork. Specifically, it includes:\n",
      "\n",
      "- Finalizing the MVP scope and user flows, such as user interactions, milestone release flow, roles, and NFTs needed for governance.\n",
      "- Deciding on the blockchain network (e.g., Polygon, Ethereum, etc.)\n",
      "- Drafting the Supabase schema for project metadata, users, milestones, and investments.\n",
      "- Outlining how prompts in XO will be used to generate front-end components.\n",
      "\n",
      "This initial week is focused on setting a solid foundation for the development phases to follow.\n",
      "ü§ñ Week 8 is designated as a buffer and final development tasks period. The key activities include:\n",
      "\n",
      "- Addressing any unforeseen complexities from previous weeks, such as UX refinements and minor smart contract adjustments.\n",
      "- Performing additional internal testing to verify all end-to-end user flows.\n",
      "- Optimizing the front-end code and finalizing gas optimizations for smart contracts.\n",
      "- Updating documentation, including code comments and user instructions for connecting wallets and creating proposals.\n",
      "\n",
      "This week ensures the project is polished and ready for subsequent testing and feedback phases. \n",
      "\n",
      "Source: Plan of Action, Week 8 details.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    user_id = \"user_abc\"\n",
    "    user_folder = f\"data/{user_id}\"  # e.g., user uploads go here\n",
    "\n",
    "    agent, kb = create_user_agent(user_id, user_folder)\n",
    "\n",
    "    # Load docs once (or only when new ones are added)\n",
    "    kb.load(recreate=False)\n",
    "\n",
    "    while True:\n",
    "        query = input(\"Ask your assistant: \")\n",
    "        if query.lower() in {\"exit\", \"quit\"}:\n",
    "            break\n",
    "        response = agent.run(query)\n",
    "        print(\"ü§ñ\", response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a530b504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
