{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d4978a28",
   "metadata": {},
   "outputs": [
    {
     "ename": "CancelledError",
     "evalue": "Cancelled by cancel scope 21f5f9eacd0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mWouldBlock\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\documents\\GEN AI\\Agno\\venv\\Lib\\site-packages\\anyio\\streams\\memory.py:111\u001b[39m, in \u001b[36mMemoryObjectReceiveStream.receive\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreceive_nowait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m WouldBlock:\n\u001b[32m    113\u001b[39m     \u001b[38;5;66;03m# Add ourselves in the queue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\documents\\GEN AI\\Agno\\venv\\Lib\\site-packages\\anyio\\streams\\memory.py:106\u001b[39m, in \u001b[36mMemoryObjectReceiveStream.receive_nowait\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m EndOfStream\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m WouldBlock\n",
      "\u001b[31mWouldBlock\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     16\u001b[39m server_params = StreamableHTTPClientParams(\n\u001b[32m     17\u001b[39m     url=\u001b[33m\"\u001b[39m\u001b[33mhttp://localhost:8000\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     18\u001b[39m     headers={\n\u001b[32m   (...)\u001b[39m\u001b[32m     22\u001b[39m     \u001b[38;5;66;03m# terminate_on_close=True  # optional: close the stream cleanly\u001b[39;00m\n\u001b[32m     23\u001b[39m )\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m MCPTools(server_params=server_params, transport=\u001b[33m\"\u001b[39m\u001b[33mstreamable-http\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m mcp_tools:\n\u001b[32m     27\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoaded tools:\u001b[39m\u001b[33m\"\u001b[39m, mcp_tools.tool_names)\n\u001b[32m     28\u001b[39m         agent = Agent(model=OpenAIChat(\u001b[38;5;28mid\u001b[39m=\u001b[33m\"\u001b[39m\u001b[33mgpt-4o\u001b[39m\u001b[33m\"\u001b[39m), tools=[mcp_tools])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\documents\\GEN AI\\Agno\\venv\\Lib\\site-packages\\agno\\tools\\mcp.py:190\u001b[39m, in \u001b[36mMCPTools.__aenter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;28mself\u001b[39m.session = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._session_context.\u001b[34m__aenter__\u001b[39m()  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[38;5;66;03m# Initialize with the new session\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.initialize()\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\documents\\GEN AI\\Agno\\venv\\Lib\\site-packages\\agno\\tools\\mcp.py:216\u001b[39m, in \u001b[36mMCPTools.initialize\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mSession is not available. Use as context manager or provide a session.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    215\u001b[39m \u001b[38;5;66;03m# Initialize the session if not already initialized\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.session.initialize()\n\u001b[32m    218\u001b[39m \u001b[38;5;66;03m# Get the list of tools from the MCP server\u001b[39;00m\n\u001b[32m    219\u001b[39m available_tools = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.session.list_tools()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\documents\\GEN AI\\Agno\\venv\\Lib\\site-packages\\mcp\\client\\session.py:151\u001b[39m, in \u001b[36mClientSession.initialize\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    139\u001b[39m elicitation = (\n\u001b[32m    140\u001b[39m     types.ElicitationCapability() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._elicitation_callback \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _default_elicitation_callback \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    141\u001b[39m )\n\u001b[32m    142\u001b[39m roots = (\n\u001b[32m    143\u001b[39m     \u001b[38;5;66;03m# TODO: Should this be based on whether we\u001b[39;00m\n\u001b[32m    144\u001b[39m     \u001b[38;5;66;03m# _will_ send notifications, or only whether\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    148\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.send_request(\n\u001b[32m    152\u001b[39m     types.ClientRequest(\n\u001b[32m    153\u001b[39m         types.InitializeRequest(\n\u001b[32m    154\u001b[39m             method=\u001b[33m\"\u001b[39m\u001b[33minitialize\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    155\u001b[39m             params=types.InitializeRequestParams(\n\u001b[32m    156\u001b[39m                 protocolVersion=types.LATEST_PROTOCOL_VERSION,\n\u001b[32m    157\u001b[39m                 capabilities=types.ClientCapabilities(\n\u001b[32m    158\u001b[39m                     sampling=sampling,\n\u001b[32m    159\u001b[39m                     elicitation=elicitation,\n\u001b[32m    160\u001b[39m                     experimental=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    161\u001b[39m                     roots=roots,\n\u001b[32m    162\u001b[39m                 ),\n\u001b[32m    163\u001b[39m                 clientInfo=\u001b[38;5;28mself\u001b[39m._client_info,\n\u001b[32m    164\u001b[39m             ),\n\u001b[32m    165\u001b[39m         )\n\u001b[32m    166\u001b[39m     ),\n\u001b[32m    167\u001b[39m     types.InitializeResult,\n\u001b[32m    168\u001b[39m )\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.protocolVersion \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m SUPPORTED_PROTOCOL_VERSIONS:\n\u001b[32m    171\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnsupported protocol version from the server: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult.protocolVersion\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\documents\\GEN AI\\Agno\\venv\\Lib\\site-packages\\mcp\\shared\\session.py:272\u001b[39m, in \u001b[36mBaseSession.send_request\u001b[39m\u001b[34m(self, request, result_type, request_read_timeout_seconds, metadata, progress_callback)\u001b[39m\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    271\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m anyio.fail_after(timeout):\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m         response_or_error = \u001b[38;5;28;01mawait\u001b[39;00m response_stream_reader.receive()\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m:\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m McpError(\n\u001b[32m    275\u001b[39m         ErrorData(\n\u001b[32m    276\u001b[39m             code=httpx.codes.REQUEST_TIMEOUT,\n\u001b[32m   (...)\u001b[39m\u001b[32m    282\u001b[39m         )\n\u001b[32m    283\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\documents\\GEN AI\\Agno\\venv\\Lib\\site-packages\\anyio\\streams\\memory.py:119\u001b[39m, in \u001b[36mMemoryObjectReceiveStream.receive\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28mself\u001b[39m._state.waiting_receivers[receive_event] = receiver\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m receive_event.wait()\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    121\u001b[39m     \u001b[38;5;28mself\u001b[39m._state.waiting_receivers.pop(receive_event, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\documents\\GEN AI\\Agno\\venv\\Lib\\asyncio\\locks.py:213\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    211\u001b[39m \u001b[38;5;28mself\u001b[39m._waiters.append(fut)\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m fut\n\u001b[32m    214\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mCancelledError\u001b[39m: Cancelled by cancel scope 21f5f9eacd0"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from agno.agent import Agent\n",
    "from agno.models.openai import OpenAIChat\n",
    "from agno.tools.mcp import MCPTools, StreamableHTTPClientParams\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY']=os.getenv('OPENAI_API_KEY')\n",
    "# üîê Replace with your actual Linear API key\n",
    "LINEAR_API_KEY = os.getenv('LINEAR_API_KEY')\n",
    "\n",
    "# üåê Hosted Linear MCP server endpoint\n",
    "server_url = \"https://mcp.linear.app/sse\"\n",
    "\n",
    "# ‚úÖ Configure server parameters\n",
    "server_params = StreamableHTTPClientParams(\n",
    "    url=\"http://localhost:8000\",\n",
    "    headers={\n",
    "        \"Authorization\": f\"Bearer {LINEAR_API_KEY}\"\n",
    "    },\n",
    "    # timeout=60,  # optional: request timeout in seconds\n",
    "    # terminate_on_close=True  # optional: close the stream cleanly\n",
    ")\n",
    "\n",
    "try:\n",
    "    async with MCPTools(server_params=server_params, transport=\"streamable-http\") as mcp_tools:\n",
    "        print(\"Loaded tools:\", mcp_tools.tool_names)\n",
    "        agent = Agent(model=OpenAIChat(id=\"gpt-4o\"), tools=[mcp_tools])\n",
    "        await agent.aprint_response(\"Create a new Linear issue titled 'App crashes on login'\", stream=True)\n",
    "except Exception as e:\n",
    "    print(\"Error during agent run:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcfefe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e03260ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Linear MCP...\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "Cancelled by cancel scope 1b601fe9f10",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mWouldBlock\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\documents\\GEN AI\\Agno\\venv\\Lib\\site-packages\\anyio\\streams\\memory.py:111\u001b[39m, in \u001b[36mMemoryObjectReceiveStream.receive\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreceive_nowait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m WouldBlock:\n\u001b[32m    113\u001b[39m     \u001b[38;5;66;03m# Add ourselves in the queue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\documents\\GEN AI\\Agno\\venv\\Lib\\site-packages\\anyio\\streams\\memory.py:106\u001b[39m, in \u001b[36mMemoryObjectReceiveStream.receive_nowait\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m EndOfStream\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m WouldBlock\n",
      "\u001b[31mWouldBlock\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 49\u001b[39m\n\u001b[32m     46\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚ùå Error:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m(e).\u001b[34m__name__\u001b[39m, \u001b[38;5;28mstr\u001b[39m(e))\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# ‚úÖ Run (use await in Jupyter or asyncio.run in script)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m run_agent()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mrun_agent\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     32\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mConnecting to Linear MCP...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m MCPTools(server_params=server_params, transport=\u001b[33m\"\u001b[39m\u001b[33mstreamable-http\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m mcp_tools:\n\u001b[32m     34\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Tools loaded:\u001b[39m\u001b[33m\"\u001b[39m, mcp_tools.tool_names)\n\u001b[32m     36\u001b[39m         agent = Agent(\n\u001b[32m     37\u001b[39m             model=OpenAIChat(\u001b[38;5;28mid\u001b[39m=\u001b[33m\"\u001b[39m\u001b[33mgpt-4o\u001b[39m\u001b[33m\"\u001b[39m),  \u001b[38;5;66;03m# Use \"gpt-4o\" or \"gpt-3.5-turbo\"\u001b[39;00m\n\u001b[32m     38\u001b[39m             tools=[mcp_tools]\n\u001b[32m     39\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\documents\\GEN AI\\Agno\\venv\\Lib\\site-packages\\agno\\tools\\mcp.py:190\u001b[39m, in \u001b[36mMCPTools.__aenter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;28mself\u001b[39m.session = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._session_context.\u001b[34m__aenter__\u001b[39m()  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[38;5;66;03m# Initialize with the new session\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.initialize()\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\documents\\GEN AI\\Agno\\venv\\Lib\\site-packages\\agno\\tools\\mcp.py:216\u001b[39m, in \u001b[36mMCPTools.initialize\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mSession is not available. Use as context manager or provide a session.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    215\u001b[39m \u001b[38;5;66;03m# Initialize the session if not already initialized\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.session.initialize()\n\u001b[32m    218\u001b[39m \u001b[38;5;66;03m# Get the list of tools from the MCP server\u001b[39;00m\n\u001b[32m    219\u001b[39m available_tools = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.session.list_tools()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\documents\\GEN AI\\Agno\\venv\\Lib\\site-packages\\mcp\\client\\session.py:151\u001b[39m, in \u001b[36mClientSession.initialize\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    139\u001b[39m elicitation = (\n\u001b[32m    140\u001b[39m     types.ElicitationCapability() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._elicitation_callback \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _default_elicitation_callback \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    141\u001b[39m )\n\u001b[32m    142\u001b[39m roots = (\n\u001b[32m    143\u001b[39m     \u001b[38;5;66;03m# TODO: Should this be based on whether we\u001b[39;00m\n\u001b[32m    144\u001b[39m     \u001b[38;5;66;03m# _will_ send notifications, or only whether\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    148\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.send_request(\n\u001b[32m    152\u001b[39m     types.ClientRequest(\n\u001b[32m    153\u001b[39m         types.InitializeRequest(\n\u001b[32m    154\u001b[39m             method=\u001b[33m\"\u001b[39m\u001b[33minitialize\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    155\u001b[39m             params=types.InitializeRequestParams(\n\u001b[32m    156\u001b[39m                 protocolVersion=types.LATEST_PROTOCOL_VERSION,\n\u001b[32m    157\u001b[39m                 capabilities=types.ClientCapabilities(\n\u001b[32m    158\u001b[39m                     sampling=sampling,\n\u001b[32m    159\u001b[39m                     elicitation=elicitation,\n\u001b[32m    160\u001b[39m                     experimental=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    161\u001b[39m                     roots=roots,\n\u001b[32m    162\u001b[39m                 ),\n\u001b[32m    163\u001b[39m                 clientInfo=\u001b[38;5;28mself\u001b[39m._client_info,\n\u001b[32m    164\u001b[39m             ),\n\u001b[32m    165\u001b[39m         )\n\u001b[32m    166\u001b[39m     ),\n\u001b[32m    167\u001b[39m     types.InitializeResult,\n\u001b[32m    168\u001b[39m )\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.protocolVersion \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m SUPPORTED_PROTOCOL_VERSIONS:\n\u001b[32m    171\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnsupported protocol version from the server: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult.protocolVersion\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\documents\\GEN AI\\Agno\\venv\\Lib\\site-packages\\mcp\\shared\\session.py:272\u001b[39m, in \u001b[36mBaseSession.send_request\u001b[39m\u001b[34m(self, request, result_type, request_read_timeout_seconds, metadata, progress_callback)\u001b[39m\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    271\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m anyio.fail_after(timeout):\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m         response_or_error = \u001b[38;5;28;01mawait\u001b[39;00m response_stream_reader.receive()\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m:\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m McpError(\n\u001b[32m    275\u001b[39m         ErrorData(\n\u001b[32m    276\u001b[39m             code=httpx.codes.REQUEST_TIMEOUT,\n\u001b[32m   (...)\u001b[39m\u001b[32m    282\u001b[39m         )\n\u001b[32m    283\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\documents\\GEN AI\\Agno\\venv\\Lib\\site-packages\\anyio\\streams\\memory.py:119\u001b[39m, in \u001b[36mMemoryObjectReceiveStream.receive\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28mself\u001b[39m._state.waiting_receivers[receive_event] = receiver\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m receive_event.wait()\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    121\u001b[39m     \u001b[38;5;28mself\u001b[39m._state.waiting_receivers.pop(receive_event, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\documents\\GEN AI\\Agno\\venv\\Lib\\asyncio\\locks.py:213\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    211\u001b[39m \u001b[38;5;28mself\u001b[39m._waiters.append(fut)\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m fut\n\u001b[32m    214\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mCancelledError\u001b[39m: Cancelled by cancel scope 1b601fe9f10"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from agno.agent import Agent\n",
    "from agno.models.openai import OpenAIChat\n",
    "from agno.tools.mcp import MCPTools, StreamableHTTPClientParams\n",
    "\n",
    "# ‚úÖ Load environment variables\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "LINEAR_API_KEY = os.getenv(\"LINEAR_API_KEY\")\n",
    "\n",
    "# ‚úÖ Confirm keys are loaded\n",
    "assert LINEAR_API_KEY and LINEAR_API_KEY.startswith(\"lin_api_\"), \"‚ùå Invalid or missing LINEAR_API_KEY\"\n",
    "assert os.environ[\"OPENAI_API_KEY\"].startswith(\"sk-\"), \"‚ùå Invalid or missing OPENAI_API_KEY\"\n",
    "\n",
    "# ‚úÖ Linear MCP endpoint\n",
    "server_url = \"https://mcp.linear.app/mcp\"\n",
    "\n",
    "# ‚úÖ Setup MCP server params\n",
    "server_params = StreamableHTTPClientParams(\n",
    "    url=server_url,\n",
    "    headers={\"Authorization\": f\"Bearer {LINEAR_API_KEY}\"},\n",
    "    timeout=30,\n",
    "    terminate_on_close=True\n",
    ")\n",
    "\n",
    "# ‚úÖ Run the agent\n",
    "async def run_agent():\n",
    "    try:\n",
    "        print(\"Connecting to Linear MCP...\")\n",
    "        async with MCPTools(server_params=server_params, transport=\"streamable-http\") as mcp_tools:\n",
    "            print(\"‚úÖ Tools loaded:\", mcp_tools.tool_names)\n",
    "\n",
    "            agent = Agent(\n",
    "                model=OpenAIChat(id=\"gpt-4o\"),  # Use \"gpt-4o\" or \"gpt-3.5-turbo\"\n",
    "                tools=[mcp_tools]\n",
    "            )\n",
    "\n",
    "            await agent.aprint_response(\n",
    "                \"Create a new Linear issue titled 'App crashes on login'\",\n",
    "                stream=True\n",
    "            )\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Error:\", type(e).__name__, str(e))\n",
    "\n",
    "# ‚úÖ Run (use await in Jupyter or asyncio.run in script)\n",
    "await run_agent()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2ccc9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error during agent run: UnsupportedOperation fileno\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from agno.agent import Agent\n",
    "from agno.models.openai import OpenAIChat\n",
    "from agno.tools.mcp import MCPTools\n",
    "from mcp.client.stdio import StdioServerParameters\n",
    "\n",
    "# ‚úÖ Load environment variables\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "LINEAR_API_KEY = os.getenv(\"LINEAR_API_KEY\")\n",
    "\n",
    "# ‚úÖ Setup stdio command to run the Linear MCP proxy via npx\n",
    "server_params = StdioServerParameters(\n",
    "    command=\"npx\",\n",
    "    args=[\"-y\", \"mcp-remote\", \"https://mcp.linear.app/sse\"],\n",
    "    env={\"LINEAR_API_KEY\": LINEAR_API_KEY}\n",
    ")\n",
    "\n",
    "# ‚úÖ Async agent runner\n",
    "async def run_agent():\n",
    "    try:\n",
    "        async with MCPTools(server_params=server_params, transport=\"stdio\") as mcp_tools:\n",
    "            print(\"‚úÖ Loaded tools:\", mcp_tools.tool_names)\n",
    "\n",
    "            agent = Agent(\n",
    "                model=OpenAIChat(id=\"gpt-4o\"),\n",
    "                tools=[mcp_tools]\n",
    "            )\n",
    "\n",
    "            await agent.aprint_response(\"Create a new Linear issue titled 'App crashes on login'\", stream=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Error during agent run:\", type(e).__name__, str(e))\n",
    "\n",
    "# ‚úÖ In Jupyter: use await; in .py file: use asyncio.run()\n",
    "await run_agent()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42960a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error asyncio.run() cannot be called from a running event loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sigma\\AppData\\Local\\Temp\\ipykernel_40164\\328987272.py:36: RuntimeWarning: coroutine 'runagent' was never awaited\n",
      "  print(f\"Error {e}\")\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "import asyncio\n",
    "from agno.agent import Agent\n",
    "from agno.models.openai import OpenAIChat\n",
    "from agno.tools.mcp import MCPTools, StreamableHTTPClientParams\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY']=os.getenv('OPENAI_API_KEY')\n",
    "LINEAR_API_KEY = os.getenv('LINEAR_API_KEY')\n",
    "\n",
    "\n",
    "async def create_mcp_agent(session):\n",
    "\n",
    "    mcp_tools=MCPTools(session=session)\n",
    "    await mcp_tools.initialize()\n",
    "    return Agent(model=OpenAIChat(id=\"gpt-4o\"), tools=[mcp_tools],instructions=[\"you are a Linear Task Management agent with Model Context Protocal tool of linear\"],\n",
    "                markdown=True, show_tool_calls=True)\n",
    "\n",
    "\n",
    "async def runagent(message:str):\n",
    "    server_params=StdioServerParameters(\n",
    "        command=\"npx\",\n",
    "        args=[\"-y\", \"mcp-remote\", \"https://mcp.linear.app/sse\"],\n",
    "        env={\"LINEAR_API_KEY\": LINEAR_API_KEY}\n",
    "    )\n",
    "    try:\n",
    "        async with stdio_client(server_params) as (read,write):\n",
    "            async with ClientSession(read,write) as session:\n",
    "                agent=await create_mcp_agent(session)\n",
    "                await agent.aprint_response(message, stream=\"True\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error {e}\")\n",
    "    finally:\n",
    "        await asyncio.sleep(0.1)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    try:\n",
    "        asyncio.run(runagent(\"Create a new Linear issue titled 'App crashes on login'\"))\n",
    "    except Exception as e:\n",
    "        print(f\"Error {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4db21188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Embedder not provided, using OpenAIEmbedder as default.                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Embedder not provided, using OpenAIEmbedder as default.                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Creating collection                                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Creating collection                                                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Loading knowledge base                                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Loading knowledge base                                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Reading: Akreage Launch Pad Whitepaper                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Reading: Akreage Launch Pad Whitepaper                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Added <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> documents to knowledge base                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Added \u001b[1;36m6\u001b[0m documents to knowledge base                                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Reading: Akreage_Launchpad_Scope_of_Work <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Reading: Akreage_Launchpad_Scope_of_Work \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Added <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> documents to knowledge base                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Added \u001b[1;36m2\u001b[0m documents to knowledge base                                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Reading: Plan of Action                                                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Reading: Plan of Action                                                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Added <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> documents to knowledge base                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Added \u001b[1;36m5\u001b[0m documents to knowledge base                                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import json\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "from agno.agent import Agent\n",
    "from agno.knowledge.pdf import PDFKnowledgeBase\n",
    "from agno.vectordb.qdrant import Qdrant\n",
    "from agno.storage.sqlite import SqliteStorage\n",
    "from agno.models.openai import OpenAIChat\n",
    "from agno.tools.mcp import MCPTools\n",
    "from agno.exceptions import ModelProviderError\n",
    "\n",
    "from io import StringIO\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "vector_db = Qdrant(\n",
    "            collection=\"project_test2\",\n",
    "            url=\"http://localhost:6333\"\n",
    "        )\n",
    "knowledge_base = PDFKnowledgeBase(\n",
    "                path=f\"data/user_abc\",\n",
    "                vector_db=vector_db\n",
    "                )\n",
    "knowledge_base.load(recreate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a982602c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
