{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a5c6706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from agno.agent import Agent\n",
    "from agno.knowledge.pdf import PDFKnowledgeBase, PDFReader\n",
    "from agno.vectordb.qdrant import Qdrant\n",
    "from agno.models.openai import OpenAIChat\n",
    "from agno.document.chunking.recursive import RecursiveChunking\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY']=os.getenv('OPENAI_API_KEY')\n",
    "# Shared Qdrant collection (all chunks go here)\n",
    "COLLECTION_NAME = \"shared_user_docs\"\n",
    "QDRANT_URL = \"http://localhost:6333\"\n",
    "\n",
    "def create_user_agent(user_id: str):\n",
    "    user_pdf_path = f\"data/{user_id}\"  # Folder with this user's PDFs\n",
    "\n",
    "    if not os.path.exists(user_pdf_path):\n",
    "        raise FileNotFoundError(f\"No document folder found for user_id: {user_id}\")\n",
    "\n",
    "    vector_db = Qdrant(\n",
    "        collection=COLLECTION_NAME,\n",
    "        url=QDRANT_URL\n",
    "    )\n",
    "\n",
    "    knowledge_base = PDFKnowledgeBase(\n",
    "        path=user_pdf_path,\n",
    "        vector_db=vector_db,\n",
    "        reader=PDFReader(chunk=True),\n",
    "        # chunking_strategy=RecursiveChunking(chunk_size=800, overlap=100),\n",
    "        metadata={\"user_id\": user_id}  # Tag all chunks on ingestion\n",
    "    )\n",
    "\n",
    "    agent = Agent(\n",
    "        model=OpenAIChat(id=\"gpt-3.5-turbo-0125\"),\n",
    "        knowledge=knowledge_base,\n",
    "        user_id=user_id,  # Used internally by Agno to scope memory, RAG, history\n",
    "        search_knowledge=True,\n",
    "        instructions=[\n",
    "            \"You are a helpful assistant that answers questions based only on the user's uploaded PDF documents.\",\n",
    "            \"Cite the document name if possible.\",\n",
    "            \"If the answer isn't in the documents, respond clearly with 'I couldn't find that in your files.'\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return agent, knowledge_base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e9a980e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Embedder not provided, using OpenAIEmbedder as default.                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Embedder not provided, using OpenAIEmbedder as default.                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable Agent object",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m user_id = \u001b[38;5;28minput\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEnter your user ID: \u001b[39m\u001b[33m\"\u001b[39m).strip()\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     agent, kb = create_user_agent(user_id)\n\u001b[32m      7\u001b[39m     \u001b[38;5;66;03m# First-time document loading (or after new uploads)\u001b[39;00m\n\u001b[32m      8\u001b[39m     kb.load(recreate=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mTypeError\u001b[39m: cannot unpack non-iterable Agent object"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    user_id = input(\"Enter your user ID: \").strip()\n",
    "\n",
    "    try:\n",
    "        agent, kb = create_user_agent(user_id)\n",
    "\n",
    "        # First-time document loading (or after new uploads)\n",
    "        kb.load(recreate=False)\n",
    "\n",
    "        print(f\"ü§ñ Agent ready for user `{user_id}`. Ask your questions.\")\n",
    "        while True:\n",
    "            query = input(\"\\nYour question (or 'exit'): \")\n",
    "            if query.lower() in {\"exit\", \"quit\"}:\n",
    "                break\n",
    "            response = agent.run(query)\n",
    "            print(\"üß†\", response.content)\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(\"‚ùå\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb0cc750",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agno.knowledge.pdf import PDFKnowledgeBase, PDFReader\n",
    "from agno.document.chunking.recursive import RecursiveChunking\n",
    "from agno.vectordb.qdrant import Qdrant\n",
    "\n",
    "def ingest_user_documents(user_id: str):\n",
    "    knowledge_base = PDFKnowledgeBase(\n",
    "        path=f\"data/{user_id}\",                         # ‚úÖ folder where PDFs for that user are stored\n",
    "        vector_db=Qdrant(\n",
    "            collection=\"multi_user_docs\",\n",
    "            url=\"http://localhost:6333\"\n",
    "        ),\n",
    "        reader=PDFReader(chunk=True),\n",
    "        # chunking_strategy=RecursiveChunking(chunk_size=800, overlap=100),\n",
    "        metadata={\"user_id\": user_id}                         # ‚úÖ CRUCIAL: this tags all chunks with user_id\n",
    "    )\n",
    "    \n",
    "    # Load documents only if new or not already indexed\n",
    "    knowledge_base.load(recreate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe16d250",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agno.agent import Agent\n",
    "from agno.knowledge import AgentKnowledge\n",
    "from agno.embedder.openai import OpenAIEmbedder\n",
    "from agno.models.openai import OpenAIChat\n",
    "from agno.vectordb.qdrant import Qdrant as AgnoQdrant\n",
    "\n",
    "def create_user_agent(user_id: str):\n",
    "    vector_db = AgnoQdrant(\n",
    "        collection=\"multi_user_docs\",\n",
    "        url=\"http://localhost:6333\"\n",
    "    )\n",
    "\n",
    "    knowledge = AgentKnowledge(\n",
    "        vector_db=vector_db,\n",
    "        embedder=OpenAIEmbedder(),\n",
    "        user_id=user_id  # ‚úÖ Agno will now only retrieve chunks for this user\n",
    "    )\n",
    "\n",
    "    agent = Agent(\n",
    "        model=OpenAIChat(id=\"gpt-4.1-nano\"),\n",
    "        knowledge=knowledge,\n",
    "        user_id=user_id,\n",
    "        search_knowledge=True,\n",
    "        instructions=[\n",
    "            \"You are a helpful assistant that only uses the user's uploaded documents.\",\n",
    "            \"Cite the file when relevant, and be honest when the answer isn't found.\"\n",
    "        ]\n",
    "    )\n",
    "    return agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33a1d134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Embedder not provided, using OpenAIEmbedder as default.                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Embedder not provided, using OpenAIEmbedder as default.                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Loading knowledge base                                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Loading knowledge base                                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Reading: Introduction                                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Reading: Introduction                                                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Added <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> documents to knowledge base                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Added \u001b[1;36m0\u001b[0m documents to knowledge base                                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Embedder not provided, using OpenAIEmbedder as default.                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Embedder not provided, using OpenAIEmbedder as default.                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Akreage is a comprehensive blockchain-powered ecosystem focused on real estate crowdfunding and investment. It utilizes its governance token called Akres, which enables holders to participate in project approvals, oversee project progress, and purchase Council NFTs that grant authority in the vetting process. The platform provides a transparent and regulated funding mechanism through its Akreage Launchpad, where developers raise funds in AUSD (Akreage Dollars) and projects establish investment funds in The Bahamas for legal and financial oversight. Additionally, Akreage offers a Payment System that facilitates seamless digital transactions within real estate developments, enhancing utility and efficiency for developers, investors, and other stakeholders. The ecosystem aims to democratize access to global real estate investments, combining blockchain technology with traditional funding structures.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    user_id = input(\"Enter your user ID: \").strip()\n",
    "\n",
    "    # Step 1: Ingest and tag user documents (run only once or when PDFs change)\n",
    "    ingest_user_documents(user_id)\n",
    "\n",
    "    # Step 2: Create isolated agent\n",
    "    agent = create_user_agent(user_id)\n",
    "\n",
    "    # Step 3: Chat loop\n",
    "    while True:\n",
    "        query = input(f\"[{user_id}] Ask your agent: \")\n",
    "        if query.lower() in {\"exit\", \"quit\"}:\n",
    "            break\n",
    "        response = agent.run(query)\n",
    "        print(\"ü§ñ\", response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65874672",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
